{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para el análisis de datos\n",
    "import numpy as np  # Biblioteca para operaciones numéricas, especialmente útil para trabajar con matrices y arrays\n",
    "import pandas as pd  # Biblioteca para manipulación y análisis de datos, especialmente para DataFrames\n",
    "import statsmodels.api as sm  # Biblioteca para realizar modelos estadísticos, útil para regresiones y otros análisis estadísticos\n",
    "from collections import Counter  # Contador de elementos en colecciones, útil para contar la frecuencia de elementos en una lista o array\n",
    "\n",
    "# Librería para optimización\n",
    "from gurobipy import Model, GRB, quicksum  # Gurobi es una biblioteca de optimización matemática. \n",
    "# Model permite definir el modelo de optimización,\n",
    "# GRB contiene constantes (como tipos de variables y sentido de optimización),\n",
    "# quicksum permite realizar sumas de forma rápida y eficiente en Gurobi.\n",
    "\n",
    "# Librerías operacionales\n",
    "import os  # Biblioteca para interactuar con el sistema operativo (ej. manejo de archivos y rutas)\n",
    "from datetime import datetime  # Módulo para trabajar con fechas y tiempos, útil para capturar fechas actuales o manipular datos de tiempo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# rl\n",
    "# # Importar las librerías necesarias\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, BaseCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import gc\n",
    "import logging  \n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed \n",
    "import warnings\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h2>1. Carga de datos desde excel a dataframes de pandas</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se cargan los datos iniciales desde los csv que nos proveen. (Esto puede tardar un ratito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_tratamiento = 'https://drive.usercontent.google.com/download?id=1KTRwYGaWoQQnZwbk8VpdxKULMaOReoF5&authuser=0&confirm=t&uuid=4e4d7983-c5a5-412d-9f5b-b9bda1068b73&at=AENtkXZSxkDr84kWrDlz6ANq4ov2%3A1730951312566'\n",
    "\n",
    "df_tratamiento = pd.read_csv(url_tratamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '173bRZQG7NWfdpHJ-o4-NA3ieH1-Fhyok'\n",
    "url_informacion_de_clientes = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "df_informacion_de_clientes = pd.read_csv(url_informacion_de_clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_simulaciones_clientes = 'https://drive.usercontent.google.com/download?id=1IXyKwtKFLCUsAV1MtNqktiwKaHzV2D5A&authuser=0&confirm=t&uuid=edd22376-238f-4c1f-b603-728b07bafd7f&at=AENtkXaEURpV52p_BdWxyisvjhSQ%3A1730951026384'\n",
    "\n",
    "df_simulaciones_clientes = pd.read_csv(url_simulaciones_clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '1Z4jMzZeD2q-4-ioSgyimppAdLZzqDkt3'\n",
    "url_ventas = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "df_ventas = pd.read_csv(url_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3>1.1 Carga de 'Informacion_Clientes.csv'</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se cargará la información de los clientes. Esto incluye las siguientes características de los clientes:\n",
    "\n",
    "* **unnamed**: algo como uid\n",
    "* **Rut**: identificador de Chile (supongo que por privacidad va desde 0 a max de observaciones)\n",
    "* **Género**: Masculino o femenino\n",
    "* **Categoría_Digital**: Si el cliente es digital o no\n",
    "* **Elasticidad_Precios**: Baja, media o alta\n",
    "* **Nacionalidad**: Chileno o extranjero\n",
    "* **Propensión**: Número entre 0 y 1 que idica que tan propenso a cursar un credito es el cliente\n",
    "* **Probabilidad_No_Pago**: Número entre 0 y 1 que indica la probabilidad de que el cliente no pague la deuda\n",
    "* **Edad**: Numero entero de edad en años\n",
    "* **Renta**: Renta promedio de los últimos 12 meses\n",
    "* **Oferta_Consumo**: Monto máximo que puede cursar un cliente dado sus antecedentes crediticios y situación socioeconómica. \n",
    "* **Deuda_CMF**: Deuda que tiene el cliente en otros bancos. Efectivamente es deuda pendiente, pero de créditos otorgados por la competencia.\n",
    "* **Tiempo_como_cliente**: Número de tiempo(no sé en que medida está) que el cliente lleva en el banco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina el tiempo como cliente ya que no aporta información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_informacion_de_clientes.drop(columns=['Tiempo_como_cliente'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3>1.2 Carga de 'Simulaciones_Clientes.csv'</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En segundo lugar se cargaran las simulaciones hechas por los clientes en la página del banco. Esto incluye las siguientes características de las simulaciones:\n",
    "* **unnamed**: Supongo que es el número de simulacion registrada, un tipo de identificador de la simulación\n",
    "* **fecha**: yyyy-mm-dd fecha de la simulación\n",
    "* **rut**: identificador de Chile del cliente que hizo la simulacion\n",
    "* **monto_simulado**: monto prestado al cliente\n",
    "* **plazo_simulado**: plazo en **meses** del crédito\n",
    "* **tasa_simulado**: costo para el cliente del credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulaciones_clientes = df_simulaciones_clientes[df_simulaciones_clientes['Monto_Simulado'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3>1.3 Carga de 'Tratamiento.csv'</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tercer lugar se cargara el tratamiento que ha tenido el banco con el cliente, es decir, cómo se han contactado con él. Esto incluye las siguientes características:\n",
    "\n",
    "* **unnamed**: Número de tratamiento registrado\n",
    "* **fecha**: yyyy-mm-dd\n",
    "* **rut**: Identificador de Chile del cliente con el que se tiene el tipo de trato\n",
    "* **n_correos**: Cantidad de correos que se enviaron en el mes que sale la fecha. Es decir, si sele fecha '2024-03-01', correspondería a los correos enviados en marzo de 2024.\n",
    "* **asg_ejec**: Si el cliente tiene un ejecutivo asignado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3>1.4 Carga de 'Ventas.csv'</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último se cargaran las ventas que ha tenido el banco con el cliente. Esto incluye las siguientes características:\n",
    "\n",
    "* **unnamed**: Índice sin significado\n",
    "* **fecha**: yyyy-mm-dd -> fecha en la que se concretó la venta\n",
    "* **rut**: identificador de Chile del cliente al que se le concretó la venta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h2>2. Joints de datos<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames 'df_informacion_de_clientes' y 'df_simulaciones_clientes' en base a la columna 'rut'\n",
    "# El método 'how=\"left\"' asegura que todos los registros de 'df_informacion_de_clientes' se conserven,\n",
    "# incluso si no tienen coincidencia en 'df_simulaciones_clientes'.\n",
    "df_simulaciones_e_informacion_de_clientes = pd.merge(\n",
    "    df_informacion_de_clientes, \n",
    "    df_simulaciones_clientes, \n",
    "    on='rut', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Crear una nueva columna 'simulo' que indica si el cliente tiene un 'Monto_Simulado' o no\n",
    "# El método 'notna()' devuelve True para valores no nulos y False para nulos.\n",
    "# Luego, 'astype(int)' convierte estos valores booleanos en enteros (1 para True, 0 para False).\n",
    "df_simulaciones_e_informacion_de_clientes['simulo'] = df_simulaciones_e_informacion_de_clientes['Monto_Simulado'].notna().astype(int)\n",
    "\n",
    "# Eliminar columnas innecesarias 'Unnamed: 0_x' y 'Unnamed: 0_y' que podrían haber surgido durante la carga o manipulación de datos\n",
    "df_simulaciones_e_informacion_de_clientes.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rut</th>\n",
       "      <th>Genero</th>\n",
       "      <th>Categoria_Digital</th>\n",
       "      <th>Elasticidad_Precios</th>\n",
       "      <th>Nacionalidad</th>\n",
       "      <th>Propension</th>\n",
       "      <th>Probabilidad_No_Pago</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Renta</th>\n",
       "      <th>Oferta_Consumo</th>\n",
       "      <th>Deuda_CMF</th>\n",
       "      <th>fecha</th>\n",
       "      <th>Monto_Simulado</th>\n",
       "      <th>Plazo_Simulado</th>\n",
       "      <th>Tasa_Simulado</th>\n",
       "      <th>simulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.997340</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>30.0</td>\n",
       "      <td>625818.326221</td>\n",
       "      <td>2164276.0</td>\n",
       "      <td>712585.357842</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>319936.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.092295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.997340</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>30.0</td>\n",
       "      <td>625818.326221</td>\n",
       "      <td>2164276.0</td>\n",
       "      <td>712585.357842</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>249773.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.324675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.997340</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>30.0</td>\n",
       "      <td>625818.326221</td>\n",
       "      <td>2164276.0</td>\n",
       "      <td>712585.357842</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>280087.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.051704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.997340</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>30.0</td>\n",
       "      <td>625818.326221</td>\n",
       "      <td>2164276.0</td>\n",
       "      <td>712585.357842</td>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>289780.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.193118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.997340</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>30.0</td>\n",
       "      <td>625818.326221</td>\n",
       "      <td>2164276.0</td>\n",
       "      <td>712585.357842</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>258061.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.188368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517080</th>\n",
       "      <td>543651</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Media</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.860781</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>35.0</td>\n",
       "      <td>472806.728024</td>\n",
       "      <td>1979540.0</td>\n",
       "      <td>574575.649505</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>403331.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.356028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517081</th>\n",
       "      <td>543651</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Media</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.860781</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>35.0</td>\n",
       "      <td>472806.728024</td>\n",
       "      <td>1979540.0</td>\n",
       "      <td>574575.649505</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>359897.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.478376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517082</th>\n",
       "      <td>543651</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Media</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.860781</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>35.0</td>\n",
       "      <td>472806.728024</td>\n",
       "      <td>1979540.0</td>\n",
       "      <td>574575.649505</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>348048.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.301079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517083</th>\n",
       "      <td>543651</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Media</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.860781</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>35.0</td>\n",
       "      <td>472806.728024</td>\n",
       "      <td>1979540.0</td>\n",
       "      <td>574575.649505</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>344504.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.462272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517084</th>\n",
       "      <td>543651</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>Cliente no Digital</td>\n",
       "      <td>Media</td>\n",
       "      <td>Chileno</td>\n",
       "      <td>0.860781</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>35.0</td>\n",
       "      <td>472806.728024</td>\n",
       "      <td>1979540.0</td>\n",
       "      <td>574575.649505</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>349828.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.709522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8517085 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rut     Genero   Categoria_Digital Elasticidad_Precios  \\\n",
       "0             1  Masculino  Cliente no Digital                Alta   \n",
       "1             1  Masculino  Cliente no Digital                Alta   \n",
       "2             1  Masculino  Cliente no Digital                Alta   \n",
       "3             1  Masculino  Cliente no Digital                Alta   \n",
       "4             1  Masculino  Cliente no Digital                Alta   \n",
       "...         ...        ...                 ...                 ...   \n",
       "8517080  543651   Femenino  Cliente no Digital               Media   \n",
       "8517081  543651   Femenino  Cliente no Digital               Media   \n",
       "8517082  543651   Femenino  Cliente no Digital               Media   \n",
       "8517083  543651   Femenino  Cliente no Digital               Media   \n",
       "8517084  543651   Femenino  Cliente no Digital               Media   \n",
       "\n",
       "        Nacionalidad  Propension  Probabilidad_No_Pago  Edad          Renta  \\\n",
       "0            Chileno    0.997340              0.028445  30.0  625818.326221   \n",
       "1            Chileno    0.997340              0.028445  30.0  625818.326221   \n",
       "2            Chileno    0.997340              0.028445  30.0  625818.326221   \n",
       "3            Chileno    0.997340              0.028445  30.0  625818.326221   \n",
       "4            Chileno    0.997340              0.028445  30.0  625818.326221   \n",
       "...              ...         ...                   ...   ...            ...   \n",
       "8517080      Chileno    0.860781              0.019647  35.0  472806.728024   \n",
       "8517081      Chileno    0.860781              0.019647  35.0  472806.728024   \n",
       "8517082      Chileno    0.860781              0.019647  35.0  472806.728024   \n",
       "8517083      Chileno    0.860781              0.019647  35.0  472806.728024   \n",
       "8517084      Chileno    0.860781              0.019647  35.0  472806.728024   \n",
       "\n",
       "         Oferta_Consumo      Deuda_CMF       fecha  Monto_Simulado  \\\n",
       "0             2164276.0  712585.357842  2019-10-01        319936.0   \n",
       "1             2164276.0  712585.357842  2019-11-01        249773.0   \n",
       "2             2164276.0  712585.357842  2020-02-01        280087.0   \n",
       "3             2164276.0  712585.357842  2021-05-01        289780.0   \n",
       "4             2164276.0  712585.357842  2021-06-01        258061.0   \n",
       "...                 ...            ...         ...             ...   \n",
       "8517080       1979540.0  574575.649505  2023-03-01        403331.0   \n",
       "8517081       1979540.0  574575.649505  2023-08-01        359897.0   \n",
       "8517082       1979540.0  574575.649505  2024-03-01        348048.0   \n",
       "8517083       1979540.0  574575.649505  2024-05-01        344504.0   \n",
       "8517084       1979540.0  574575.649505  2024-06-01        349828.0   \n",
       "\n",
       "         Plazo_Simulado  Tasa_Simulado  simulo  \n",
       "0                  33.0       1.092295       1  \n",
       "1                  30.0       2.324675       1  \n",
       "2                  28.0       1.051704       1  \n",
       "3                  26.0       2.193118       1  \n",
       "4                  22.0       2.188368       1  \n",
       "...                 ...            ...     ...  \n",
       "8517080            17.0       2.356028       1  \n",
       "8517081            16.0       2.478376       1  \n",
       "8517082            18.0       2.301079       1  \n",
       "8517083            16.0       2.462272       1  \n",
       "8517084            16.0       1.709522       1  \n",
       "\n",
       "[8517085 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simulaciones_e_informacion_de_clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames 'df_simulaciones_e_informacion_de_clientes' y 'df_ventas' en base a las columnas 'rut' y 'fecha'\n",
    "# El método 'how=\"left\"' asegura que todos los registros de 'df_simulaciones_e_informacion_de_clientes' se conserven,\n",
    "# incluso si no tienen coincidencia en 'df_ventas'.\n",
    "df_simulaciones_e_informacion_de_clientes_ventas = pd.merge( \n",
    "    df_simulaciones_e_informacion_de_clientes, \n",
    "    df_ventas, \n",
    "    on=['rut', 'fecha'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Crear una nueva columna 'venta' que indica si existe una venta asociada al cliente y la fecha específica\n",
    "# El método 'notna()' verifica si hay un valor no nulo en la columna 'Unnamed: 0' (que indica presencia de una venta)\n",
    "# Luego, 'astype(int)' convierte estos valores booleanos en enteros (1 para True, 0 para False).\n",
    "df_simulaciones_e_informacion_de_clientes_ventas['venta'] = df_simulaciones_e_informacion_de_clientes_ventas['Unnamed: 0'].notna().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames 'df_simulaciones_e_informacion_de_clientes_ventas' y 'df_tratamiento' en base a las columnas 'rut' y 'fecha'\n",
    "# La unión se realiza con 'how=\"left\"' para conservar todos los registros de 'df_simulaciones_e_informacion_de_clientes_ventas'\n",
    "# incluso si no tienen coincidencia en 'df_tratamiento'.\n",
    "df_simulaciones_e_informacion_de_clientes_ventas_tratamiento = pd.merge( \n",
    "    df_simulaciones_e_informacion_de_clientes_ventas, \n",
    "    df_tratamiento, \n",
    "    on=['rut', 'fecha'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Crear una nueva columna 'mes' que extrae el mes y año de la columna 'fecha'\n",
    "# Primero se convierte 'fecha' al formato datetime, luego 'dt.to_period('M')' obtiene el periodo del mes/año.\n",
    "df_simulaciones_e_informacion_de_clientes_ventas_tratamiento['mes'] = pd.to_datetime(df_simulaciones_e_informacion_de_clientes_ventas_tratamiento['fecha']).dt.to_period('M')\n",
    "\n",
    "# Eliminar las columnas 'Unnamed: 0_x' y 'Unnamed: 0_y' ya que no aportan información relevante\n",
    "df_simulaciones_e_informacion_de_clientes_ventas_tratamiento.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CLUSTERING POR POLITICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seteo de cluster. Aquí se definen las variables y sus cortes. La idea es que el algoritmo de RL haga sus acciones en esta sección"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se definen que variables se utilizarán para crear el cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_informacion_de_clientes_procesados_cluster_definitivo = df_informacion_de_clientes[['rut', 'Elasticidad_Precios', 'Edad', 'Genero', 'Renta', 'Probabilidad_No_Pago']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se definen en que partes y en cuantas partes se particionarán las variables escogidas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rut</th>\n",
       "      <th>Elasticidad_Precios</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>Renta</th>\n",
       "      <th>Probabilidad_No_Pago</th>\n",
       "      <th>Categoria_Probabilidad_No_Pago</th>\n",
       "      <th>Categoria_Edad</th>\n",
       "      <th>Categoria_Renta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alta</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>6.258183e+05</td>\n",
       "      <td>0.028445</td>\n",
       "      <td>Mal pagador</td>\n",
       "      <td>Joven</td>\n",
       "      <td>Renta Baja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Baja</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>3.172616e+05</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>Mal pagador</td>\n",
       "      <td>Adulto</td>\n",
       "      <td>Renta Baja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Baja</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>1.240551e+07</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>Buen pagador</td>\n",
       "      <td>Adulto</td>\n",
       "      <td>Renta Alta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alta</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>5.441466e+05</td>\n",
       "      <td>0.034418</td>\n",
       "      <td>Mal pagador</td>\n",
       "      <td>Adulto</td>\n",
       "      <td>Renta Baja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Media</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>1.870225e+05</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>Mal pagador</td>\n",
       "      <td>Joven</td>\n",
       "      <td>Renta Baja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543646</th>\n",
       "      <td>543647</td>\n",
       "      <td>Baja</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>1.176598e+05</td>\n",
       "      <td>0.037291</td>\n",
       "      <td>Mal pagador</td>\n",
       "      <td>Joven</td>\n",
       "      <td>Renta Baja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543647</th>\n",
       "      <td>543648</td>\n",
       "      <td>Baja</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>1.558612e+06</td>\n",
       "      <td>0.035877</td>\n",
       "      <td>Mal pagador</td>\n",
       "      <td>Joven</td>\n",
       "      <td>Renta Alta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543648</th>\n",
       "      <td>543649</td>\n",
       "      <td>Media</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>9.449508e+05</td>\n",
       "      <td>0.023306</td>\n",
       "      <td>Mal pagador</td>\n",
       "      <td>Adulto</td>\n",
       "      <td>Renta Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543649</th>\n",
       "      <td>543650</td>\n",
       "      <td>Media</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>1.039964e+06</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>Mal pagador</td>\n",
       "      <td>Adulto</td>\n",
       "      <td>Renta Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543650</th>\n",
       "      <td>543651</td>\n",
       "      <td>Media</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>4.728067e+05</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>Mal pagador</td>\n",
       "      <td>Adulto</td>\n",
       "      <td>Renta Baja</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543651 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rut Elasticidad_Precios  Edad     Genero         Renta  \\\n",
       "0            1                Alta  30.0  Masculino  6.258183e+05   \n",
       "1            2                Baja  41.0   Femenino  3.172616e+05   \n",
       "2            3                Baja  38.0   Femenino  1.240551e+07   \n",
       "3            4                Alta  57.0  Masculino  5.441466e+05   \n",
       "4            5               Media  26.0  Masculino  1.870225e+05   \n",
       "...        ...                 ...   ...        ...           ...   \n",
       "543646  543647                Baja  29.0   Femenino  1.176598e+05   \n",
       "543647  543648                Baja  31.0  Masculino  1.558612e+06   \n",
       "543648  543649               Media  49.0  Masculino  9.449508e+05   \n",
       "543649  543650               Media  40.0   Femenino  1.039964e+06   \n",
       "543650  543651               Media  35.0   Femenino  4.728067e+05   \n",
       "\n",
       "        Probabilidad_No_Pago Categoria_Probabilidad_No_Pago Categoria_Edad  \\\n",
       "0                   0.028445                    Mal pagador          Joven   \n",
       "1                   0.014320                    Mal pagador         Adulto   \n",
       "2                   0.002156                   Buen pagador         Adulto   \n",
       "3                   0.034418                    Mal pagador         Adulto   \n",
       "4                   0.014978                    Mal pagador          Joven   \n",
       "...                      ...                            ...            ...   \n",
       "543646              0.037291                    Mal pagador          Joven   \n",
       "543647              0.035877                    Mal pagador          Joven   \n",
       "543648              0.023306                    Mal pagador         Adulto   \n",
       "543649              0.015121                    Mal pagador         Adulto   \n",
       "543650              0.019647                    Mal pagador         Adulto   \n",
       "\n",
       "       Categoria_Renta  \n",
       "0           Renta Baja  \n",
       "1           Renta Baja  \n",
       "2           Renta Alta  \n",
       "3           Renta Baja  \n",
       "4           Renta Baja  \n",
       "...                ...  \n",
       "543646      Renta Baja  \n",
       "543647      Renta Alta  \n",
       "543648     Renta Media  \n",
       "543649     Renta Media  \n",
       "543650      Renta Baja  \n",
       "\n",
       "[543651 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una copia del DataFrame 'df_informacion_de_clientes_procesados_cluster_definitivo' para trabajar sin modificar el original\n",
    "df = df_informacion_de_clientes_procesados_cluster_definitivo.copy()\n",
    "\n",
    "# Clasificar la columna 'Probabilidad_No_Pago' en cinco categorías, asignando etiquetas según los valores de probabilidad\n",
    "# Cada categoría representa el nivel de confiabilidad en el pago: desde 'Muy buen pagador' hasta 'Muy mal pagador'.\n",
    "df['Categoria_Probabilidad_No_Pago'] = pd.cut(df['Probabilidad_No_Pago'], \n",
    "                                              bins=[-float('inf'), 0.0085402934056559, float('inf')],\n",
    "                                              labels=['Buen pagador', 'Mal pagador'])\n",
    "\n",
    "# Clasificar la columna 'Edad' en tres categorías: 'Joven', 'Adulto' y 'Adulto Mayor'\n",
    "# Cada categoría se define en función de rangos de edad especificados en 'bins'.\n",
    "df['Categoria_Edad'] = pd.cut(df['Edad'], \n",
    "                              bins=[-float('inf'), 31, float('inf')],\n",
    "                              labels=['Joven', 'Adulto'])\n",
    "\n",
    "# Crear un DataFrame único de 'rut' y 'Renta' eliminando duplicados, para calcular percentiles de renta\n",
    "df_unicos_renta = df[['rut', 'Renta']].drop_duplicates()\n",
    "\n",
    "# Clasificar la columna 'Percentil_Renta' en tres categorías: 'Renta Baja', 'Renta Media' y 'Renta Alta'\n",
    "# Los rangos de percentil especificados en 'bins' definen estas categorías.\n",
    "df_unicos_renta['Categoria_Renta'] = pd.cut(df_unicos_renta['Renta'], \n",
    "                                            bins=[-float('inf'), 705468.9044051456, 1382978.7928061879, float('inf')],\n",
    "                                            labels=['Renta Baja', 'Renta Media', 'Renta Alta'])\n",
    "\n",
    "# Incorporar la categoría de renta al DataFrame principal 'df' realizando una unión ('merge') en base a la columna 'rut'\n",
    "df = df.merge(df_unicos_renta[['rut', 'Categoria_Renta']], on='rut', how='left')\n",
    "\n",
    "# Mostrar el DataFrame resultante con las nuevas columnas creadas\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar las variables especificadas en una nueva columna 'categoria_clusterizacion'\n",
    "# La columna resultante combinará varias categorías en una descripción detallada del perfil del cliente.\n",
    "# Convertimos cada columna a tipo string para asegurarnos de que los datos sean compatibles para la concatenación.\n",
    "\n",
    "df['categoria_clusterizacion'] = (\n",
    "    df['Elasticidad_Precios'].astype(str) + ' ' +              # Categoría de digitalización del cliente\n",
    "    df['Categoria_Edad'].astype(str) + ' de genero ' +       # Categoría de edad, seguida de la palabra \"de genero\"\n",
    "    df['Genero'].astype(str) + ' con una ' +                     # Género del cliente\n",
    "    df['Categoria_Renta'].astype(str) + 'que es un ' +                      # Categoría de renta\n",
    "    df['Categoria_Probabilidad_No_Pago'].astype(str)  # Categoría de probabilidad de no pago\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar un número único a cada entrada distinta en la columna 'categoria_clusterizacion'\n",
    "# Se convierte la columna a tipo 'category', lo cual facilita la asignación de códigos numéricos únicos.\n",
    "# 'cat.codes' asigna un código numérico único para cada valor único de 'categoria_clusterizacion'.\n",
    "df['categoria_clusterizacion_numerica'] = df['categoria_clusterizacion'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del DataFrame con solo las columnas 'rut', 'categoria_clusterizacion' y 'categoria_clusterizacion_numerica'\n",
    "# Esta copia se almacena en el nuevo DataFrame 'asignacion_clusters', el cual contendrá únicamente la identificación del cliente (rut),\n",
    "# la descripción del perfil ('categoria_clusterizacion') y el código numérico asignado a cada perfil ('categoria_clusterizacion_numerica').\n",
    "asignacion_clusters = df[['rut', 'categoria_clusterizacion', 'categoria_clusterizacion_numerica']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Estimacion de curvas de elasticidad por cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar una unión entre 'df_simulaciones_e_informacion_de_clientes_ventas' y 'asignacion_clusters' usando la columna 'rut' como clave\n",
    "# Esta unión ('merge') se realiza con 'how=\"left\"', lo que asegura que todos los registros de 'df_simulaciones_e_informacion_de_clientes_ventas' \n",
    "# se conserven, incluyendo aquellos sin coincidencia en 'asignacion_clusters'.\n",
    "# La finalidad es agregar la información de clusterización (categoría y código numérico) al DataFrame de simulaciones y ventas.\n",
    "df_estimar_elasticidad = pd.merge(df_simulaciones_e_informacion_de_clientes_ventas, asignacion_clusters, on='rut', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elasticity_curve_with_histogram(tasas_grid, acceptance_probability, tasa_optima, df_cluster, cluster_num, output_folder):\n",
    "    \"\"\"\n",
    "    Grafica la curva de elasticidad con la tasa óptima marcada y un histograma\n",
    "    que muestra ventas y no ventas para cada precio, con mejoras en la visualización.\n",
    "    \n",
    "    Args:\n",
    "    - tasas_grid (numpy array): Valores de la tasa simulada (eje X).\n",
    "    - acceptance_probability (numpy array): Probabilidades de aceptación (eje Y).\n",
    "    - tasa_optima (float): Tasa óptima encontrada.\n",
    "    - df_cluster (DataFrame): Datos del cluster actual, incluyendo 'Tasa_Simulado' y 'venta'.\n",
    "    - cluster_num (int): Número del cluster para el título.\n",
    "    - output_folder (str): Ruta de la carpeta donde se guardará el gráfico.\n",
    "    \"\"\"\n",
    "    # Preparar datos para el histograma\n",
    "    ventas = df_cluster[df_cluster['venta'] == 1]['Tasa_Simulado']\n",
    "    no_ventas = df_cluster[df_cluster['venta'] == 0]['Tasa_Simulado']\n",
    "    \n",
    "    # Crear la figura\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Curva de elasticidad\n",
    "    ax1.plot(tasas_grid, acceptance_probability, label=\"Curva de Elasticidad\", color='blue', linewidth=2)\n",
    "    ax1.axvline(x=tasa_optima, color='green', linestyle='--', label=f\"Tasa Óptima: {tasa_optima:.2f}%\", zorder=10)\n",
    "    ax1.set_xlabel(\"Tasa Simulada (%)\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Probabilidad de Aceptación\", fontsize=12, color='black')\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax1.legend(loc='upper left', bbox_to_anchor=(1.2, 1))  # Leyenda fuera de la gráfica\n",
    "    \n",
    "    # Histograma de ventas y no ventas (usar el segundo eje Y)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.hist([ventas, no_ventas], bins=20, color=['blue', 'red'], alpha=0.3, label=[\"Ventas\", \"No Ventas\"], stacked=True)\n",
    "    ax2.set_ylabel(\"Frecuencia de Ventas\", fontsize=12, color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    ax2.legend(loc='upper left', bbox_to_anchor=(1.2, 0.85))  # Leyenda fuera de la gráfica\n",
    "\n",
    "    # Título\n",
    "    plt.title(f\"Curva de Elasticidad y Ventas por Tasa - Cluster {cluster_num}\", fontsize=14)\n",
    "    \n",
    "    # Ajustar diseño para evitar superposiciones\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar el gráfico\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    output_path = os.path.join(output_folder, f\"curva_elasticidad_cluster_{cluster_num}.png\")\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"Gráfico guardado en: {output_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este código realiza un análisis de elasticidad de ingresos en función de clusters de clientes. Primero, agrupa los datos por clusters definidos a través de variables de segmentación y filtra solo los datos relevantes para cada cluster. Luego, para cada cluster, se ajusta un modelo de regresión logística para predecir la probabilidad de aceptación de una simulación de crédito en función de la tasa de interés. A partir de este modelo, se crea una cuadrícula de tasas para estimar la probabilidad de aceptación y calcular el revenue potencial de cada simulación, teniendo en cuenta el monto medio simulado, el plazo medio simulado y la probabilidad media de no pago del cluster. Posteriormente, se determina la tasa que maximiza el revenue esperado y se calcula el número esperado de créditos aceptados, junto con el número de clientes únicos en cada cluster. Finalmente, los resultados se agregan tanto en listas globales como en un nuevo DataFrame, y luego se integran en el DataFrame original df_estimar_elasticidad, lo que permite analizar el revenue esperado total y otros indicadores clave en cada cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_estimar_elasticidad(df_estimar_elasticidad):\n",
    "    # Inicializar listas para almacenar resultados globales de revenue, clientes, créditos y simulaciones\n",
    "    lista_revenue = []\n",
    "    lista_clientes = []\n",
    "    lista_creditos = []\n",
    "    lista_simulaciones = []\n",
    "\n",
    "    cluster_results = []  # Lista para almacenar resultados específicos de cada cluster\n",
    "\n",
    "    # Obtener los números únicos de cada cluster\n",
    "    cluster_numbers = df_estimar_elasticidad['categoria_clusterizacion_numerica'].unique()\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_folder = f\"hg_reglog_{timestamp}\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterar sobre cada cluster identificado por 'categoria_clusterizacion_numerica'\n",
    "    for cluster_num in cluster_numbers:\n",
    "        # Filtrar los datos correspondientes al cluster actual\n",
    "        df_cluster = df_estimar_elasticidad[df_estimar_elasticidad['categoria_clusterizacion_numerica'] == cluster_num]\n",
    "        \n",
    "        # Asegurarse de que existen datos para ambos casos: venta == 1 y venta == 0\n",
    "        if df_cluster.empty or df_cluster['venta'].isnull().all():\n",
    "            continue  # Saltar este cluster si no cumple con la condición\n",
    "        \n",
    "        # Remover filas donde 'venta' o 'Tasa_Simulado' son nulos o infinitos\n",
    "        df_cluster = df_cluster.replace([np.inf, -np.inf], np.nan)\n",
    "        df_cluster = df_cluster.dropna(subset=['venta', 'Tasa_Simulado', 'Plazo_Simulado', 'Monto_Simulado', 'Probabilidad_No_Pago'])\n",
    "        \n",
    "        # Saltar el cluster si no hay suficientes puntos de datos\n",
    "        if df_cluster.shape[0] < 10:\n",
    "            continue\n",
    "        \n",
    "        # Extraer las variables 'venta' (como variable dependiente) y 'Tasa_Simulado' (como predictor)\n",
    "        y = df_cluster['venta']\n",
    "        X = df_cluster[['Tasa_Simulado']]\n",
    "        \n",
    "        # Añadir un término constante para el intercepto\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        # Remover filas con valores NaN o Inf en X o y\n",
    "        is_finite = np.isfinite(X).all(1) & np.isfinite(y)\n",
    "        X = X[is_finite]\n",
    "        y = y[is_finite]\n",
    "        \n",
    "        # Asegurarse de que después de remover NaN/Inf, todavía hay suficientes datos\n",
    "        if len(y) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Ajustar el modelo de regresión logística\n",
    "        logit_model = sm.Logit(y, X)\n",
    "        try:\n",
    "            result = logit_model.fit(disp=0)\n",
    "        except:\n",
    "            continue  # Saltar el cluster si el modelo no converge\n",
    "        \n",
    "        # Crear una cuadrícula de valores de 'Tasa_Simulado' para predicciones\n",
    "        tasa_min = df_cluster['Tasa_Simulado'].min()\n",
    "        tasa_max = df_cluster['Tasa_Simulado'].max()\n",
    "        tasas_grid = np.linspace(tasa_min, tasa_max, 1000)\n",
    "        \n",
    "        # Predecir la probabilidad de aceptación usando el modelo ajustado\n",
    "        X_grid = sm.add_constant(tasas_grid)\n",
    "        acceptance_probability = result.predict(X_grid)\n",
    "        \n",
    "        # Asegurar que las probabilidades están en el rango [0, 1]\n",
    "        acceptance_probability = np.clip(acceptance_probability, 0, 1)\n",
    "\n",
    "        # Calcular valores medios necesarios para el cálculo de revenue\n",
    "        n = df_cluster['Plazo_Simulado'].mean()\n",
    "        vp = df_cluster['Monto_Simulado'].mean()\n",
    "        pnp = df_cluster['Probabilidad_No_Pago'].mean()\n",
    "        data = {\n",
    "            'Plazo_Simulado_medio': n, \n",
    "            'Monto_Simulado_medio': vp, \n",
    "            'Probabilidad_No_Pago_media': pnp\n",
    "        }\n",
    "        \n",
    "        # Calcular el revenue potencial\n",
    "        i = tasas_grid / 100  # Convertir a decimal\n",
    "        one_plus_i_pow_n = np.power(1 + i, n)\n",
    "        annuity_factor = (i * one_plus_i_pow_n) / (one_plus_i_pow_n - 1)\n",
    "        revenue = (n * vp * annuity_factor) - vp\n",
    "        potential_revenue = revenue * (1 - pnp)\n",
    "        \n",
    "        # Calcular el promedio de simulaciones por fecha\n",
    "        df_cluster_simulaciones_1 = df_cluster[df_cluster['simulo'] == 1]\n",
    "        num_dates = df_cluster_simulaciones_1['fecha'].nunique()\n",
    "        total_simulaciones = df_cluster_simulaciones_1['simulo'].sum()\n",
    "        simulaciones_medias = total_simulaciones / num_dates if num_dates else 0\n",
    "        \n",
    "        # Saltar el cluster si no hay simulaciones\n",
    "        if simulaciones_medias == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calcular el revenue esperado\n",
    "        expected_revenue = acceptance_probability * potential_revenue * simulaciones_medias\n",
    "        \n",
    "        # Encontrar la tasa que maximiza el revenue esperado\n",
    "        idx_max = np.argmax(expected_revenue)\n",
    "        max_price = tasas_grid[idx_max]\n",
    "        max_expected_revenue = expected_revenue[idx_max]\n",
    "        \n",
    "        # Probabilidad de aceptación en la tasa óptima\n",
    "        prob_aceptacion_optima = acceptance_probability[idx_max]\n",
    "        \n",
    "        # Llamar a la función para graficar la curva y el histograma\n",
    "        # plot_elasticity_curve_with_histogram(\n",
    "        #     tasas_grid, \n",
    "        #     acceptance_probability, \n",
    "        #     max_price, \n",
    "        #     df_cluster,  # Pasamos todo el DataFrame del cluster actual\n",
    "        #     cluster_num, \n",
    "        #     output_folder\n",
    "        # )\n",
    "\n",
    "        # Número esperado de créditos aceptados\n",
    "        num_creditos_aceptados = round(prob_aceptacion_optima * simulaciones_medias)\n",
    "        \n",
    "        # Número de clientes únicos en el cluster\n",
    "        num_clients = df_cluster['rut'].nunique()\n",
    "        \n",
    "        # Imprimir resultados para cada cluster\n",
    "        print(f'Cluster {cluster_num}:')\n",
    "        print(f'- Precio Máx. Revenue Esperado = {max_price:.2f}%')\n",
    "        print(f'- Revenue Esperado Máximo = {max_expected_revenue:,.2f}')\n",
    "        print(f'- Número de clientes en el cluster = {num_clients}')\n",
    "        print(f'- Número de simulaciones en el cluster = {simulaciones_medias:.2f}')\n",
    "        print(f'- Probabilidad de aceptación en el precio óptimo = {prob_aceptacion_optima:.4f}')\n",
    "        print(f'- Número esperado de créditos aceptados = {num_creditos_aceptados}')\n",
    "        print(f'- Monto medio simulado = {data[\"Monto_Simulado_medio\"]:,.2f}')\n",
    "        print(f'- Plazo medio simulado = {data[\"Plazo_Simulado_medio\"]:,.2f}')\n",
    "        print(f'- Probabilidad de no pago media = {data[\"Probabilidad_No_Pago_media\"]:.4f}\\n')\n",
    "\n",
    "        # Agregar resultados a las listas globales\n",
    "        lista_clientes.append(num_clients)\n",
    "        lista_revenue.append(max_expected_revenue)\n",
    "        lista_creditos.append(num_creditos_aceptados)\n",
    "        lista_simulaciones.append(simulaciones_medias)\n",
    "        \n",
    "        # Almacenar resultados por cluster en cluster_results\n",
    "        cluster_results.append({\n",
    "            'categoria_clusterizacion_numerica': cluster_num,\n",
    "            'tasa_optima': max_price,\n",
    "            'probabilidad_aceptacion_optima': prob_aceptacion_optima,\n",
    "            'revenue_esperado_maximo': max_expected_revenue,\n",
    "            'numero_clientes': num_clients,\n",
    "            'numero_simulaciones_medias': simulaciones_medias,\n",
    "            'numero_creditos_esperados': num_creditos_aceptados,\n",
    "            'monto_medio_simulado': data[\"Monto_Simulado_medio\"],\n",
    "            'plazo_medio_simulado': data[\"Plazo_Simulado_medio\"],\n",
    "            'probabilidad_no_pago_media': data[\"Probabilidad_No_Pago_media\"]\n",
    "        })\n",
    "\n",
    "    # Imprimir resultados globales\n",
    "    total_revenue = sum(lista_revenue)\n",
    "    total_clientes = sum(lista_clientes)\n",
    "    total_simulaciones = sum(lista_simulaciones)\n",
    "    total_creditos = sum(lista_creditos)\n",
    "\n",
    "    print(f\"El revenue total esperado es: {total_revenue:,.2f} con un total de {total_clientes} clientes, \"\n",
    "        f\"{total_simulaciones:,.2f} simulaciones, y {total_creditos} créditos.\")\n",
    "\n",
    "    # Crear un DataFrame a partir de cluster_results\n",
    "    df_cluster_results = pd.DataFrame(cluster_results)\n",
    "\n",
    "    # Incorporar los resultados por cluster de 'df_cluster_results' a 'df_estimar_elasticidad'\n",
    "    df_estimar_elasticidad = df_estimar_elasticidad.merge(\n",
    "        df_cluster_results[['categoria_clusterizacion_numerica', 'tasa_optima', 'probabilidad_aceptacion_optima']],\n",
    "        on='categoria_clusterizacion_numerica', \n",
    "        how='left'\n",
    "    )\n",
    "    return {'df_estimar_elasticidad': df_estimar_elasticidad, 'total_revenue': total_revenue, 'total_clientes': total_clientes, 'total_simulaciones': total_simulaciones, 'total_creditos': total_creditos}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 21:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 41,831,424.37\n",
      "- Número de clientes en el cluster = 7057\n",
      "- Número de simulaciones en el cluster = 1666.24\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4008\n",
      "- Número esperado de créditos aceptados = 668\n",
      "- Monto medio simulado = 164,803.61\n",
      "- Plazo medio simulado = 27.46\n",
      "- Probabilidad de no pago media = 0.0356\n",
      "\n",
      "Cluster 27:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 304,008,264.12\n",
      "- Número de clientes en el cluster = 11627\n",
      "- Número de simulaciones en el cluster = 2700.89\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7404\n",
      "- Número esperado de créditos aceptados = 2000\n",
      "- Monto medio simulado = 1,035,022.75\n",
      "- Plazo medio simulado = 27.59\n",
      "- Probabilidad de no pago media = 0.0159\n",
      "\n",
      "Cluster 24:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 16,787,963,026.74\n",
      "- Número de clientes en el cluster = 29062\n",
      "- Número de simulaciones en el cluster = 7462.77\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7419\n",
      "- Número esperado de créditos aceptados = 5537\n",
      "- Monto medio simulado = 20,521,307.28\n",
      "- Plazo medio simulado = 27.42\n",
      "- Probabilidad de no pago media = 0.0038\n",
      "\n",
      "Cluster 9:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 441,463,149.21\n",
      "- Número de clientes en el cluster = 16961\n",
      "- Número de simulaciones en el cluster = 3821.05\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4018\n",
      "- Número esperado de créditos aceptados = 1535\n",
      "- Monto medio simulado = 750,296.37\n",
      "- Plazo medio simulado = 27.52\n",
      "- Probabilidad de no pago media = 0.0300\n",
      "\n",
      "Cluster 69:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 181,237,847.59\n",
      "- Número de clientes en el cluster = 7897\n",
      "- Número de simulaciones en el cluster = 1815.20\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6135\n",
      "- Número esperado de créditos aceptados = 1114\n",
      "- Monto medio simulado = 813,314.00\n",
      "- Plazo medio simulado = 27.56\n",
      "- Probabilidad de no pago media = 0.0390\n",
      "\n",
      "Cluster 26:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 262,416,801.15\n",
      "- Número de clientes en el cluster = 10749\n",
      "- Número de simulaciones en el cluster = 2610.39\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7435\n",
      "- Número esperado de créditos aceptados = 1941\n",
      "- Monto medio simulado = 912,614.29\n",
      "- Plazo medio simulado = 27.50\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 71:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 260,817,187.82\n",
      "- Número de clientes en el cluster = 3537\n",
      "- Número de simulaciones en el cluster = 802.83\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6131\n",
      "- Número esperado de créditos aceptados = 492\n",
      "- Monto medio simulado = 2,631,813.09\n",
      "- Plazo medio simulado = 27.56\n",
      "- Probabilidad de no pago media = 0.0388\n",
      "\n",
      "Cluster 51:\n",
      "- Precio Máx. Revenue Esperado = 1.37%\n",
      "- Revenue Esperado Máximo = 239,176,347.26\n",
      "- Número de clientes en el cluster = 13458\n",
      "- Número de simulaciones en el cluster = 3054.85\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6158\n",
      "- Número esperado de créditos aceptados = 1881\n",
      "- Monto medio simulado = 625,069.62\n",
      "- Plazo medio simulado = 27.42\n",
      "- Probabilidad de no pago media = 0.0171\n",
      "\n",
      "Cluster 7:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 6,037,134,522.88\n",
      "- Número de clientes en el cluster = 22810\n",
      "- Número de simulaciones en el cluster = 5170.29\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3997\n",
      "- Número esperado de créditos aceptados = 2067\n",
      "- Monto medio simulado = 7,624,178.33\n",
      "- Plazo medio simulado = 27.48\n",
      "- Probabilidad de no pago media = 0.0287\n",
      "\n",
      "Cluster 47:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 298,857,905.39\n",
      "- Número de clientes en el cluster = 5677\n",
      "- Número de simulaciones en el cluster = 1353.82\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7395\n",
      "- Número esperado de créditos aceptados = 1001\n",
      "- Monto medio simulado = 2,074,629.40\n",
      "- Plazo medio simulado = 27.54\n",
      "- Probabilidad de no pago media = 0.0342\n",
      "\n",
      "Cluster 31:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 8,412,983,863.29\n",
      "- Número de clientes en el cluster = 28950\n",
      "- Número de simulaciones en el cluster = 7170.03\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7436\n",
      "- Número esperado de créditos aceptados = 5332\n",
      "- Monto medio simulado = 10,797,417.98\n",
      "- Plazo medio simulado = 27.53\n",
      "- Probabilidad de no pago media = 0.0188\n",
      "\n",
      "Cluster 33:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 371,153,917.40\n",
      "- Número de clientes en el cluster = 14789\n",
      "- Número de simulaciones en el cluster = 3498.79\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7433\n",
      "- Número esperado de créditos aceptados = 2601\n",
      "- Monto medio simulado = 985,631.13\n",
      "- Plazo medio simulado = 27.48\n",
      "- Probabilidad de no pago media = 0.0261\n",
      "\n",
      "Cluster 54:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 17,608,108,071.55\n",
      "- Número de clientes en el cluster = 16548\n",
      "- Número de simulaciones en el cluster = 4155.61\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6114\n",
      "- Número esperado de créditos aceptados = 2541\n",
      "- Monto medio simulado = 33,362,018.94\n",
      "- Plazo medio simulado = 27.48\n",
      "- Probabilidad de no pago media = 0.0031\n",
      "\n",
      "Cluster 43:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 721,488,902.69\n",
      "- Número de clientes en el cluster = 6401\n",
      "- Número de simulaciones en el cluster = 1574.44\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7402\n",
      "- Número esperado de créditos aceptados = 1165\n",
      "- Monto medio simulado = 4,292,900.34\n",
      "- Plazo medio simulado = 27.51\n",
      "- Probabilidad de no pago media = 0.0308\n",
      "\n",
      "Cluster 57:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 427,206,171.96\n",
      "- Número de clientes en el cluster = 18148\n",
      "- Número de simulaciones en el cluster = 4125.27\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6134\n",
      "- Número esperado de créditos aceptados = 2530\n",
      "- Monto medio simulado = 835,011.28\n",
      "- Plazo medio simulado = 27.57\n",
      "- Probabilidad de no pago media = 0.0294\n",
      "\n",
      "Cluster 49:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 2,553,969,168.08\n",
      "- Número de clientes en el cluster = 12383\n",
      "- Número de simulaciones en el cluster = 2832.56\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6133\n",
      "- Número esperado de créditos aceptados = 1737\n",
      "- Monto medio simulado = 7,187,645.77\n",
      "- Plazo medio simulado = 27.49\n",
      "- Probabilidad de no pago media = 0.0151\n",
      "\n",
      "Cluster 11:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 881,569,143.90\n",
      "- Número de clientes en el cluster = 10539\n",
      "- Número de simulaciones en el cluster = 2385.73\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4011\n",
      "- Número esperado de créditos aceptados = 957\n",
      "- Monto medio simulado = 2,408,042.76\n",
      "- Plazo medio simulado = 27.46\n",
      "- Probabilidad de no pago media = 0.0297\n",
      "\n",
      "Cluster 37:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 791,157,737.19\n",
      "- Número de clientes en el cluster = 4326\n",
      "- Número de simulaciones en el cluster = 1024.64\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7364\n",
      "- Número esperado de créditos aceptados = 755\n",
      "- Monto medio simulado = 7,254,446.39\n",
      "- Plazo medio simulado = 27.30\n",
      "- Probabilidad de no pago media = 0.0211\n",
      "\n",
      "Cluster 62:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 17,181,891.46\n",
      "- Número de clientes en el cluster = 3502\n",
      "- Número de simulaciones en el cluster = 804.80\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6105\n",
      "- Número esperado de créditos aceptados = 491\n",
      "- Monto medio simulado = 168,948.29\n",
      "- Plazo medio simulado = 27.48\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 25:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 4,648,598,700.74\n",
      "- Número de clientes en el cluster = 16605\n",
      "- Número de simulaciones en el cluster = 4058.42\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7439\n",
      "- Número esperado de créditos aceptados = 3019\n",
      "- Monto medio simulado = 10,431,903.51\n",
      "- Plazo medio simulado = 27.64\n",
      "- Probabilidad de no pago media = 0.0129\n",
      "\n",
      "Cluster 3:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 121,091,449.72\n",
      "- Número de clientes en el cluster = 6201\n",
      "- Número de simulaciones en el cluster = 1417.32\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4078\n",
      "- Número esperado de créditos aceptados = 578\n",
      "- Monto medio simulado = 542,131.57\n",
      "- Plazo medio simulado = 27.42\n",
      "- Probabilidad de no pago media = 0.0182\n",
      "\n",
      "Cluster 30:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 21,206,633,934.65\n",
      "- Número de clientes en el cluster = 29709\n",
      "- Número de simulaciones en el cluster = 7700.89\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7433\n",
      "- Número esperado de créditos aceptados = 5724\n",
      "- Monto medio simulado = 24,947,565.01\n",
      "- Plazo medio simulado = 27.55\n",
      "- Probabilidad de no pago media = 0.0036\n",
      "\n",
      "Cluster 55:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 7,458,254,105.88\n",
      "- Número de clientes en el cluster = 27495\n",
      "- Número de simulaciones en el cluster = 6365.08\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6116\n",
      "- Número esperado de créditos aceptados = 3893\n",
      "- Monto medio simulado = 9,424,980.33\n",
      "- Plazo medio simulado = 27.58\n",
      "- Probabilidad de no pago media = 0.0256\n",
      "\n",
      "Cluster 17:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 65,241,199.77\n",
      "- Número de clientes en el cluster = 3548\n",
      "- Número de simulaciones en el cluster = 832.42\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4013\n",
      "- Número esperado de créditos aceptados = 334\n",
      "- Monto medio simulado = 510,018.02\n",
      "- Plazo medio simulado = 27.30\n",
      "- Probabilidad de no pago media = 0.0226\n",
      "\n",
      "Cluster 45:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 206,476,611.55\n",
      "- Número de clientes en el cluster = 12121\n",
      "- Número de simulaciones en el cluster = 2877.18\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7451\n",
      "- Número esperado de créditos aceptados = 2144\n",
      "- Monto medio simulado = 673,150.11\n",
      "- Plazo medio simulado = 27.41\n",
      "- Probabilidad de no pago media = 0.0351\n",
      "\n",
      "Cluster 13:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 183,241,875.21\n",
      "- Número de clientes en el cluster = 3739\n",
      "- Número de simulaciones en el cluster = 902.55\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4012\n",
      "- Número esperado de créditos aceptados = 362\n",
      "- Monto medio simulado = 1,314,752.46\n",
      "- Plazo medio simulado = 27.40\n",
      "- Probabilidad de no pago media = 0.0213\n",
      "\n",
      "Cluster 34:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 436,665,373.68\n",
      "- Número de clientes en el cluster = 5546\n",
      "- Número de simulaciones en el cluster = 1411.71\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7415\n",
      "- Número esperado de créditos aceptados = 1047\n",
      "- Monto medio simulado = 2,817,364.56\n",
      "- Plazo medio simulado = 27.48\n",
      "- Probabilidad de no pago media = 0.0041\n",
      "\n",
      "Cluster 59:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 873,591,847.09\n",
      "- Número de clientes en el cluster = 11834\n",
      "- Número de simulaciones en el cluster = 2698.20\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6116\n",
      "- Número esperado de créditos aceptados = 1650\n",
      "- Monto medio simulado = 2,623,952.85\n",
      "- Plazo medio simulado = 27.45\n",
      "- Probabilidad de no pago media = 0.0284\n",
      "\n",
      "Cluster 28:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 558,774,215.36\n",
      "- Número de clientes en el cluster = 7471\n",
      "- Número de simulaciones en el cluster = 1832.74\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7453\n",
      "- Número esperado de créditos aceptados = 1366\n",
      "- Monto medio simulado = 2,769,648.94\n",
      "- Plazo medio simulado = 27.42\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 61:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 178,878,391.60\n",
      "- Número de clientes en el cluster = 4914\n",
      "- Número de simulaciones en el cluster = 1127.95\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6120\n",
      "- Número esperado de créditos aceptados = 690\n",
      "- Monto medio simulado = 1,275,410.14\n",
      "- Plazo medio simulado = 27.49\n",
      "- Probabilidad de no pago media = 0.0241\n",
      "\n",
      "Cluster 4:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 167,790,247.60\n",
      "- Número de clientes en el cluster = 2118\n",
      "- Número de simulaciones en el cluster = 488.95\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3952\n",
      "- Número esperado de créditos aceptados = 193\n",
      "- Monto medio simulado = 2,218,965.74\n",
      "- Plazo medio simulado = 27.38\n",
      "- Probabilidad de no pago media = 0.0041\n",
      "\n",
      "Cluster 5:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 235,880,988.52\n",
      "- Número de clientes en el cluster = 3452\n",
      "- Número de simulaciones en el cluster = 791.38\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4012\n",
      "- Número esperado de créditos aceptados = 318\n",
      "- Monto medio simulado = 1,906,710.85\n",
      "- Plazo medio simulado = 27.61\n",
      "- Probabilidad de no pago media = 0.0172\n",
      "\n",
      "Cluster 0:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 1,485,365,375.95\n",
      "- Número de clientes en el cluster = 4570\n",
      "- Número de simulaciones en el cluster = 1075.45\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4010\n",
      "- Número esperado de créditos aceptados = 431\n",
      "- Monto medio simulado = 8,748,504.03\n",
      "- Plazo medio simulado = 27.54\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 15:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 44,170,449.93\n",
      "- Número de clientes en el cluster = 7863\n",
      "- Número de simulaciones en el cluster = 1841.24\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3986\n",
      "- Número esperado de créditos aceptados = 734\n",
      "- Monto medio simulado = 155,941.27\n",
      "- Plazo medio simulado = 27.51\n",
      "- Probabilidad de no pago media = 0.0229\n",
      "\n",
      "Cluster 65:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 81,386,322.68\n",
      "- Número de clientes en el cluster = 5496\n",
      "- Número de simulaciones en el cluster = 1267.79\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6095\n",
      "- Número esperado de créditos aceptados = 773\n",
      "- Monto medio simulado = 519,943.25\n",
      "- Plazo medio simulado = 27.47\n",
      "- Probabilidad de no pago media = 0.0242\n",
      "\n",
      "Cluster 14:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 15,583,767.58\n",
      "- Número de clientes en el cluster = 2472\n",
      "- Número de simulaciones en el cluster = 593.21\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4046\n",
      "- Número esperado de créditos aceptados = 240\n",
      "- Monto medio simulado = 166,695.41\n",
      "- Plazo medio simulado = 27.26\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 50:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 189,924,611.30\n",
      "- Número de clientes en el cluster = 8575\n",
      "- Número de simulaciones en el cluster = 1967.73\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6143\n",
      "- Número esperado de créditos aceptados = 1209\n",
      "- Monto medio simulado = 759,233.29\n",
      "- Plazo medio simulado = 27.51\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 52:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 369,277,073.68\n",
      "- Número de clientes en el cluster = 5326\n",
      "- Número de simulaciones en el cluster = 1220.56\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6154\n",
      "- Número esperado de créditos aceptados = 751\n",
      "- Monto medio simulado = 2,379,880.07\n",
      "- Plazo medio simulado = 27.43\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 48:\n",
      "- Precio Máx. Revenue Esperado = 1.37%\n",
      "- Revenue Esperado Máximo = 2,767,291,552.72\n",
      "- Número de clientes en el cluster = 10394\n",
      "- Número de simulaciones en el cluster = 2442.64\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6134\n",
      "- Número esperado de créditos aceptados = 1498\n",
      "- Monto medio simulado = 8,926,686.85\n",
      "- Plazo medio simulado = 27.53\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 32:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 184,634,974.69\n",
      "- Número de clientes en el cluster = 7108\n",
      "- Número de simulaciones en el cluster = 1793.05\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7406\n",
      "- Número esperado de créditos aceptados = 1328\n",
      "- Monto medio simulado = 940,196.11\n",
      "- Plazo medio simulado = 27.45\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 35:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 699,148,839.03\n",
      "- Número de clientes en el cluster = 9474\n",
      "- Número de simulaciones en el cluster = 2266.23\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7456\n",
      "- Número esperado de créditos aceptados = 1690\n",
      "- Monto medio simulado = 2,850,885.27\n",
      "- Plazo medio simulado = 27.50\n",
      "- Probabilidad de no pago media = 0.0242\n",
      "\n",
      "Cluster 63:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 57,147,606.00\n",
      "- Número de clientes en el cluster = 12358\n",
      "- Número de simulaciones en el cluster = 2858.89\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6138\n",
      "- Número esperado de créditos aceptados = 1755\n",
      "- Monto medio simulado = 160,381.61\n",
      "- Plazo medio simulado = 27.51\n",
      "- Probabilidad de no pago media = 0.0242\n",
      "\n",
      "Cluster 64:\n",
      "- Precio Máx. Revenue Esperado = 1.37%\n",
      "- Revenue Esperado Máximo = 23,994,179.84\n",
      "- Número de clientes en el cluster = 1506\n",
      "- Número de simulaciones en el cluster = 346.23\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6225\n",
      "- Número esperado de créditos aceptados = 216\n",
      "- Monto medio simulado = 534,978.99\n",
      "- Plazo medio simulado = 27.72\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 29:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 525,460,363.78\n",
      "- Número de clientes en el cluster = 7019\n",
      "- Número de simulaciones en el cluster = 1638.77\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7450\n",
      "- Número esperado de créditos aceptados = 1221\n",
      "- Monto medio simulado = 2,938,878.81\n",
      "- Plazo medio simulado = 27.48\n",
      "- Probabilidad de no pago media = 0.0149\n",
      "\n",
      "Cluster 12:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 83,017,401.00\n",
      "- Número de clientes en el cluster = 1448\n",
      "- Número de simulaciones en el cluster = 356.98\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4005\n",
      "- Número esperado de créditos aceptados = 143\n",
      "- Monto medio simulado = 1,477,423.88\n",
      "- Plazo medio simulado = 27.49\n",
      "- Probabilidad de no pago media = 0.0041\n",
      "\n",
      "Cluster 1:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 1,272,511,506.11\n",
      "- Número de clientes en el cluster = 5388\n",
      "- Número de simulaciones en el cluster = 1245.05\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4032\n",
      "- Número esperado de créditos aceptados = 502\n",
      "- Monto medio simulado = 6,533,616.65\n",
      "- Plazo medio simulado = 27.45\n",
      "- Probabilidad de no pago media = 0.0156\n",
      "\n",
      "Cluster 66:\n",
      "- Precio Máx. Revenue Esperado = 1.37%\n",
      "- Revenue Esperado Máximo = 101,786,095.55\n",
      "- Número de clientes en el cluster = 512\n",
      "- Número de simulaciones en el cluster = 121.77\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6010\n",
      "- Número esperado de créditos aceptados = 73\n",
      "- Monto medio simulado = 6,747,802.93\n",
      "- Plazo medio simulado = 27.53\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 56:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 136,424,817.21\n",
      "- Número de clientes en el cluster = 5161\n",
      "- Número de simulaciones en el cluster = 1223.29\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6101\n",
      "- Número esperado de créditos aceptados = 746\n",
      "- Monto medio simulado = 878,582.17\n",
      "- Plazo medio simulado = 27.55\n",
      "- Probabilidad de no pago media = 0.0040\n",
      "\n",
      "Cluster 44:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 30,281,241.99\n",
      "- Número de clientes en el cluster = 2190\n",
      "- Número de simulaciones en el cluster = 534.02\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7399\n",
      "- Número esperado de créditos aceptados = 395\n",
      "- Monto medio simulado = 517,562.17\n",
      "- Plazo medio simulado = 27.49\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 53:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 448,395,642.88\n",
      "- Número de clientes en el cluster = 7487\n",
      "- Número de simulaciones en el cluster = 1691.23\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6119\n",
      "- Número esperado de créditos aceptados = 1035\n",
      "- Monto medio simulado = 2,106,605.44\n",
      "- Plazo medio simulado = 27.55\n",
      "- Probabilidad de no pago media = 0.0165\n",
      "\n",
      "Cluster 38:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 112,562,911.61\n",
      "- Número de clientes en el cluster = 2927\n",
      "- Número de simulaciones en el cluster = 697.95\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7465\n",
      "- Número esperado de créditos aceptados = 521\n",
      "- Monto medio simulado = 1,458,142.69\n",
      "- Plazo medio simulado = 27.51\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 39:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 365,865,144.92\n",
      "- Número de clientes en el cluster = 9057\n",
      "- Número de simulaciones en el cluster = 2091.12\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7443\n",
      "- Número esperado de créditos aceptados = 1556\n",
      "- Monto medio simulado = 1,616,024.43\n",
      "- Plazo medio simulado = 27.55\n",
      "- Probabilidad de no pago media = 0.0239\n",
      "\n",
      "Cluster 58:\n",
      "- Precio Máx. Revenue Esperado = 1.37%\n",
      "- Revenue Esperado Máximo = 305,211,771.89\n",
      "- Número de clientes en el cluster = 3610\n",
      "- Número de simulaciones en el cluster = 865.02\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6123\n",
      "- Número esperado de créditos aceptados = 530\n",
      "- Monto medio simulado = 2,767,579.20\n",
      "- Plazo medio simulado = 27.69\n",
      "- Probabilidad de no pago media = 0.0040\n",
      "\n",
      "Cluster 40:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 152,154,199.61\n",
      "- Número de clientes en el cluster = 1490\n",
      "- Número de simulaciones en el cluster = 353.74\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7444\n",
      "- Número esperado de créditos aceptados = 263\n",
      "- Monto medio simulado = 3,868,119.58\n",
      "- Plazo medio simulado = 27.73\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 41:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 433,980,573.79\n",
      "- Número de clientes en el cluster = 4092\n",
      "- Número de simulaciones en el cluster = 953.77\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7465\n",
      "- Número esperado de créditos aceptados = 712\n",
      "- Monto medio simulado = 4,208,117.91\n",
      "- Plazo medio simulado = 27.42\n",
      "- Probabilidad de no pago media = 0.0236\n",
      "\n",
      "Cluster 8:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 99,805,809.29\n",
      "- Número de clientes en el cluster = 3549\n",
      "- Número de simulaciones en el cluster = 811.80\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4011\n",
      "- Número esperado de créditos aceptados = 326\n",
      "- Monto medio simulado = 769,550.86\n",
      "- Plazo medio simulado = 27.84\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 67:\n",
      "- Precio Máx. Revenue Esperado = 1.39%\n",
      "- Revenue Esperado Máximo = 552,319,175.03\n",
      "- Número de clientes en el cluster = 3233\n",
      "- Número de simulaciones en el cluster = 741.80\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6022\n",
      "- Número esperado de créditos aceptados = 447\n",
      "- Monto medio simulado = 6,128,128.51\n",
      "- Plazo medio simulado = 27.54\n",
      "- Probabilidad de no pago media = 0.0382\n",
      "\n",
      "Cluster 42:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 174,106,586.31\n",
      "- Número de clientes en el cluster = 1623\n",
      "- Número de simulaciones en el cluster = 411.76\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7503\n",
      "- Número esperado de créditos aceptados = 309\n",
      "- Monto medio simulado = 3,814,498.70\n",
      "- Plazo medio simulado = 27.43\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 19:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 194,565,460.65\n",
      "- Número de clientes en el cluster = 3582\n",
      "- Número de simulaciones en el cluster = 865.11\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3997\n",
      "- Número esperado de créditos aceptados = 346\n",
      "- Monto medio simulado = 1,475,056.20\n",
      "- Plazo medio simulado = 27.43\n",
      "- Probabilidad de no pago media = 0.0312\n",
      "\n",
      "Cluster 10:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 206,605,985.69\n",
      "- Número de clientes en el cluster = 2346\n",
      "- Número de simulaciones en el cluster = 540.77\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3950\n",
      "- Número esperado de créditos aceptados = 214\n",
      "- Monto medio simulado = 2,441,123.72\n",
      "- Plazo medio simulado = 27.70\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 2:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 91,752,415.29\n",
      "- Número de clientes en el cluster = 3784\n",
      "- Número de simulaciones en el cluster = 875.71\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3944\n",
      "- Número esperado de créditos aceptados = 345\n",
      "- Monto medio simulado = 680,360.27\n",
      "- Plazo medio simulado = 27.33\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 23:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 65,223,842.14\n",
      "- Número de clientes en el cluster = 3298\n",
      "- Número de simulaciones en el cluster = 778.98\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4060\n",
      "- Número esperado de créditos aceptados = 316\n",
      "- Monto medio simulado = 542,399.47\n",
      "- Plazo medio simulado = 27.43\n",
      "- Probabilidad de no pago media = 0.0341\n",
      "\n",
      "Cluster 16:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 26,021,949.97\n",
      "- Número de clientes en el cluster = 1302\n",
      "- Número de simulaciones en el cluster = 313.20\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3971\n",
      "- Número esperado de créditos aceptados = 124\n",
      "- Monto medio simulado = 534,129.47\n",
      "- Plazo medio simulado = 27.41\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 6:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 1,467,669,001.48\n",
      "- Número de clientes en el cluster = 5664\n",
      "- Número de simulaciones en el cluster = 1315.55\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3992\n",
      "- Número esperado de créditos aceptados = 525\n",
      "- Monto medio simulado = 7,097,033.17\n",
      "- Plazo medio simulado = 27.54\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 60:\n",
      "- Precio Máx. Revenue Esperado = 1.39%\n",
      "- Revenue Esperado Máximo = 70,088,874.98\n",
      "- Número de clientes en el cluster = 1399\n",
      "- Número de simulaciones en el cluster = 323.05\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6110\n",
      "- Número esperado de créditos aceptados = 197\n",
      "- Monto medio simulado = 1,710,957.94\n",
      "- Plazo medio simulado = 27.25\n",
      "- Probabilidad de no pago media = 0.0044\n",
      "\n",
      "Cluster 18:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 46,440,338.73\n",
      "- Número de clientes en el cluster = 743\n",
      "- Número de simulaciones en el cluster = 185.39\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.4115\n",
      "- Número esperado de créditos aceptados = 76\n",
      "- Monto medio simulado = 1,544,093.41\n",
      "- Plazo medio simulado = 27.58\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 36:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 940,218,639.51\n",
      "- Número de clientes en el cluster = 2943\n",
      "- Número de simulaciones en el cluster = 749.91\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7431\n",
      "- Número esperado de créditos aceptados = 557\n",
      "- Monto medio simulado = 11,355,134.77\n",
      "- Plazo medio simulado = 27.58\n",
      "- Probabilidad de no pago media = 0.0043\n",
      "\n",
      "Cluster 68:\n",
      "- Precio Máx. Revenue Esperado = 1.39%\n",
      "- Revenue Esperado Máximo = 24,190,132.62\n",
      "- Número de clientes en el cluster = 1067\n",
      "- Número de simulaciones en el cluster = 248.48\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.6034\n",
      "- Número esperado de créditos aceptados = 150\n",
      "- Monto medio simulado = 778,469.36\n",
      "- Plazo medio simulado = 27.27\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 20:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 8,106,159.50\n",
      "- Número de clientes en el cluster = 1288\n",
      "- Número de simulaciones en el cluster = 314.67\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3880\n",
      "- Número esperado de créditos aceptados = 122\n",
      "- Monto medio simulado = 169,462.98\n",
      "- Plazo medio simulado = 27.41\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 46:\n",
      "- Precio Máx. Revenue Esperado = 1.00%\n",
      "- Revenue Esperado Máximo = 48,564,944.60\n",
      "- Número de clientes en el cluster = 1174\n",
      "- Número de simulaciones en el cluster = 290.29\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.7490\n",
      "- Número esperado de créditos aceptados = 217\n",
      "- Monto medio simulado = 1,528,474.66\n",
      "- Plazo medio simulado = 27.13\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 70:\n",
      "- Precio Máx. Revenue Esperado = 1.38%\n",
      "- Revenue Esperado Máximo = 40,996,130.46\n",
      "- Número de clientes en el cluster = 547\n",
      "- Número de simulaciones en el cluster = 124.24\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.5996\n",
      "- Número esperado de créditos aceptados = 74\n",
      "- Monto medio simulado = 2,674,902.16\n",
      "- Plazo medio simulado = 27.16\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "Cluster 22:\n",
      "- Precio Máx. Revenue Esperado = 2.50%\n",
      "- Revenue Esperado Máximo = 13,596,042.63\n",
      "- Número de clientes en el cluster = 665\n",
      "- Número de simulaciones en el cluster = 163.98\n",
      "- Probabilidad de aceptación en el precio óptimo = 0.3907\n",
      "- Número esperado de créditos aceptados = 64\n",
      "- Monto medio simulado = 538,212.41\n",
      "- Plazo medio simulado = 27.57\n",
      "- Probabilidad de no pago media = 0.0042\n",
      "\n",
      "El revenue total esperado es: 106,936,692,198.04 con un total de 542904 clientes, 129,035.42 simulaciones, y 80394 créditos.\n"
     ]
    }
   ],
   "source": [
    "df_estimar_elasticidad = function_estimar_elasticidad(df_estimar_elasticidad)['df_estimar_elasticidad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Estimacion de respuesta a tratamiento por cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los DataFrames 'df_tratamiento' y 'df_simulaciones_clientes' usando las columnas 'rut' y 'fecha' como claves\n",
    "# La unión se realiza con 'how=\"left\"', lo cual asegura que todos los registros de 'df_tratamiento' se conserven,\n",
    "# incluyendo aquellos sin coincidencia en 'df_simulaciones_clientes'.\n",
    "# Esta operación permite combinar la información de tratamiento con los datos de simulaciones de clientes.\n",
    "df_simulaciones_info = pd.merge(df_tratamiento, df_simulaciones_clientes, on=['rut', 'fecha'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar operaciones de cadenas vectorizadas para crear la columna 'Tratamiento'\n",
    "# Esta columna concatenará información sobre el ejecutivo asignado y el número de correos enviados.\n",
    "# Se convierte 'asg_ejec' a string para poder concatenar, y 'n_correos' se convierte primero a entero y luego a string.\n",
    "# El formato final es: \"Ejecutivo=<valor_asg_ejec>, Correos=<valor_n_correos>\"\n",
    "df_simulaciones_info['Tratamiento'] = (\n",
    "    'Ejecutivo=' + df_simulaciones_info['asg_ejec'].astype(str) +\n",
    "    ', Correos=' + df_simulaciones_info['n_correos'].astype(int).astype(str)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>fecha</th>\n",
       "      <th>rut</th>\n",
       "      <th>n_correos</th>\n",
       "      <th>asg_ejec</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>Monto_Simulado</th>\n",
       "      <th>Plazo_Simulado</th>\n",
       "      <th>Tasa_Simulado</th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2019-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543651</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=4</td>\n",
       "      <td>2019-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087302</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>2019-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630953</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2019-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174604</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=0</td>\n",
       "      <td>2019-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33162711</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2024-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33706362</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2024-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34250013</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=2</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34793664</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7864785.0</td>\n",
       "      <td>267268.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.027869</td>\n",
       "      <td>Ejecutivo=1, Correos=2</td>\n",
       "      <td>2024-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35337315</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>2024-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0_x       fecha  rut  n_correos  asg_ejec  Unnamed: 0_y  \\\n",
       "0                    0  2019-01-01    1          3         0           NaN   \n",
       "543651               0  2019-02-01    1          4         0           NaN   \n",
       "1087302              0  2019-03-01    1          1         0           NaN   \n",
       "1630953              0  2019-04-01    1          3         0           NaN   \n",
       "2174604              0  2019-05-01    1          0         0           NaN   \n",
       "...                ...         ...  ...        ...       ...           ...   \n",
       "33162711             0  2024-02-01    1          3         0           NaN   \n",
       "33706362             0  2024-03-01    1          3         0           NaN   \n",
       "34250013             0  2024-04-01    1          2         0           NaN   \n",
       "34793664             0  2024-05-01    1          2         1     7864785.0   \n",
       "35337315             0  2024-06-01    1          1         0           NaN   \n",
       "\n",
       "          Monto_Simulado  Plazo_Simulado  Tasa_Simulado  \\\n",
       "0                    NaN             NaN            NaN   \n",
       "543651               NaN             NaN            NaN   \n",
       "1087302              NaN             NaN            NaN   \n",
       "1630953              NaN             NaN            NaN   \n",
       "2174604              NaN             NaN            NaN   \n",
       "...                  ...             ...            ...   \n",
       "33162711             NaN             NaN            NaN   \n",
       "33706362             NaN             NaN            NaN   \n",
       "34250013             NaN             NaN            NaN   \n",
       "34793664        267268.0            31.0       2.027869   \n",
       "35337315             NaN             NaN            NaN   \n",
       "\n",
       "                     Tratamiento      mes  \n",
       "0         Ejecutivo=0, Correos=3  2019-01  \n",
       "543651    Ejecutivo=0, Correos=4  2019-02  \n",
       "1087302   Ejecutivo=0, Correos=1  2019-03  \n",
       "1630953   Ejecutivo=0, Correos=3  2019-04  \n",
       "2174604   Ejecutivo=0, Correos=0  2019-05  \n",
       "...                          ...      ...  \n",
       "33162711  Ejecutivo=0, Correos=3  2024-02  \n",
       "33706362  Ejecutivo=0, Correos=3  2024-03  \n",
       "34250013  Ejecutivo=0, Correos=2  2024-04  \n",
       "34793664  Ejecutivo=1, Correos=2  2024-05  \n",
       "35337315  Ejecutivo=0, Correos=1  2024-06  \n",
       "\n",
       "[66 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraer el mes y año de la columna 'fecha' y crear una nueva columna 'mes' en formato de periodo mensual\n",
    "# Se convierte 'fecha' al formato datetime y luego se usa 'dt.to_period('M')' para obtener el mes/año.\n",
    "df_simulaciones_info['mes'] = pd.to_datetime(df_simulaciones_info['fecha']).dt.to_period('M')\n",
    "\n",
    "# Filtrar y mostrar las filas donde 'rut' es igual a 1\n",
    "# Este filtro permite observar los registros específicos del cliente con 'rut' igual a 1, \n",
    "# lo cual es útil para verificar datos o analizar un cliente en particular.\n",
    "df_simulaciones_info[df_simulaciones_info['rut'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>fecha</th>\n",
       "      <th>rut</th>\n",
       "      <th>n_correos</th>\n",
       "      <th>asg_ejec</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>Monto_Simulado</th>\n",
       "      <th>Plazo_Simulado</th>\n",
       "      <th>Tasa_Simulado</th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>mes</th>\n",
       "      <th>simulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543651</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=4</td>\n",
       "      <td>2019-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087302</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>2019-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630953</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174604</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=0</td>\n",
       "      <td>2019-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33162711</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2024-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33706362</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34250013</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=2</td>\n",
       "      <td>2024-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34793664</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7864785.0</td>\n",
       "      <td>267268.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.027869</td>\n",
       "      <td>Ejecutivo=1, Correos=2</td>\n",
       "      <td>2024-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35337315</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>2024-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0_x       fecha  rut  n_correos  asg_ejec  Unnamed: 0_y  \\\n",
       "0                    0  2019-01-01    1          3         0           NaN   \n",
       "543651               0  2019-02-01    1          4         0           NaN   \n",
       "1087302              0  2019-03-01    1          1         0           NaN   \n",
       "1630953              0  2019-04-01    1          3         0           NaN   \n",
       "2174604              0  2019-05-01    1          0         0           NaN   \n",
       "...                ...         ...  ...        ...       ...           ...   \n",
       "33162711             0  2024-02-01    1          3         0           NaN   \n",
       "33706362             0  2024-03-01    1          3         0           NaN   \n",
       "34250013             0  2024-04-01    1          2         0           NaN   \n",
       "34793664             0  2024-05-01    1          2         1     7864785.0   \n",
       "35337315             0  2024-06-01    1          1         0           NaN   \n",
       "\n",
       "          Monto_Simulado  Plazo_Simulado  Tasa_Simulado  \\\n",
       "0                    NaN             NaN            NaN   \n",
       "543651               NaN             NaN            NaN   \n",
       "1087302              NaN             NaN            NaN   \n",
       "1630953              NaN             NaN            NaN   \n",
       "2174604              NaN             NaN            NaN   \n",
       "...                  ...             ...            ...   \n",
       "33162711             NaN             NaN            NaN   \n",
       "33706362             NaN             NaN            NaN   \n",
       "34250013             NaN             NaN            NaN   \n",
       "34793664        267268.0            31.0       2.027869   \n",
       "35337315             NaN             NaN            NaN   \n",
       "\n",
       "                     Tratamiento      mes  simulo  \n",
       "0         Ejecutivo=0, Correos=3  2019-01       0  \n",
       "543651    Ejecutivo=0, Correos=4  2019-02       0  \n",
       "1087302   Ejecutivo=0, Correos=1  2019-03       0  \n",
       "1630953   Ejecutivo=0, Correos=3  2019-04       0  \n",
       "2174604   Ejecutivo=0, Correos=0  2019-05       0  \n",
       "...                          ...      ...     ...  \n",
       "33162711  Ejecutivo=0, Correos=3  2024-02       0  \n",
       "33706362  Ejecutivo=0, Correos=3  2024-03       0  \n",
       "34250013  Ejecutivo=0, Correos=2  2024-04       0  \n",
       "34793664  Ejecutivo=1, Correos=2  2024-05       1  \n",
       "35337315  Ejecutivo=0, Correos=1  2024-06       0  \n",
       "\n",
       "[66 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una nueva columna 'simulo' para indicar si el cliente tiene un registro de simulación\n",
    "# La columna 'Unnamed: 0_y' se utiliza para verificar si hay un valor no nulo, lo que implica que hay una simulación.\n",
    "# 'notna()' devuelve True para valores no nulos y False para valores nulos; luego, 'astype(int)' convierte estos valores a 1 (True) o 0 (False).\n",
    "df_simulaciones_info['simulo'] = df_simulaciones_info['Unnamed: 0_y'].notna().astype(int)\n",
    "\n",
    "# Filtrar y mostrar las filas donde 'rut' es igual a 1\n",
    "# Este filtro permite observar los registros específicos del cliente con 'rut' igual a 1, \n",
    "# útil para verificar si la columna 'simulo' refleja correctamente la presencia de simulaciones para este cliente.\n",
    "df_simulaciones_info[df_simulaciones_info['rut'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del DataFrame 'df_estimar_elasticidad' con solo las columnas especificadas\n",
    "# 'df1' contiene las columnas 'rut', 'categoria_clusterizacion_numerica', 'tasa_optima' y 'probabilidad_aceptacion_optima'.\n",
    "# Esta copia es útil para trabajar con los datos de elasticidad y clusterización sin modificar el DataFrame original.\n",
    "df1 = df_estimar_elasticidad[['rut', 'categoria_clusterizacion_numerica', 'tasa_optima', 'probabilidad_aceptacion_optima']].copy()\n",
    "\n",
    "# Crear una copia del DataFrame 'df_simulaciones_info' con solo las columnas especificadas\n",
    "# 'df2' contiene las columnas 'rut', 'mes', 'Tratamiento' y 'simulo'.\n",
    "# Esta copia es útil para trabajar con los datos de tratamiento y simulación en un conjunto de datos reducido.\n",
    "df2 = df_simulaciones_info[['rut', 'mes', 'Tratamiento', 'simulo']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_estimar_respuesta_a_tratamiento(df_estimar_elasticidad, df_simulaciones_info): #df1 es df_estimar_elasticidad y df2 es df_simulaciones_info\n",
    "    # Paso 1: Preparación de datos y mapeo de clusters\n",
    "    # Eliminar duplicados en 'df1' para tener un valor único de 'categoria_clusterizacion_numerica' por cada 'rut'.\n",
    "    df_estimar_elasticidad_unique = df_estimar_elasticidad.drop_duplicates(subset='rut')\n",
    "\n",
    "    # Crear un mapeo de 'rut' a 'categoria_clusterizacion_numerica' para asociar cada cliente a su cluster numérico.\n",
    "    rut_cluster_map = df_estimar_elasticidad_unique.set_index('rut')['categoria_clusterizacion_numerica']\n",
    "\n",
    "    # Mapear la categoría de cluster a cada 'rut' en 'df2' usando el mapeo creado\n",
    "    df_simulaciones_info['categoria_clusterizacion_numerica'] = df_simulaciones_info['rut'].map(rut_cluster_map)\n",
    "\n",
    "    # Eliminar filas donde 'categoria_clusterizacion_numerica' es nulo, es decir, aquellos 'rut' sin mapeo de cluster.\n",
    "    df_simulaciones_info = df_simulaciones_info.dropna(subset=['categoria_clusterizacion_numerica'])\n",
    "\n",
    "    # Conversión de tipos de datos\n",
    "    # Convertir 'categoria_clusterizacion_numerica' a entero para garantizar un tipo de dato consistente.\n",
    "    df_simulaciones_info['categoria_clusterizacion_numerica'] = df_simulaciones_info['categoria_clusterizacion_numerica'].astype(int)\n",
    "\n",
    "    # Convertir 'simulo' a numérico, reemplazando valores nulos por 0 y asegurando que sea un tipo de dato entero.\n",
    "    df_simulaciones_info['simulo'] = pd.to_numeric(df_simulaciones_info['simulo'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Convertir 'Tratamiento' a tipo de categoría para optimizar espacio y realizar operaciones categóricas.\n",
    "    df_simulaciones_info['Tratamiento'] = df_simulaciones_info['Tratamiento'].astype('category')\n",
    "\n",
    "    # Paso 2: Calcular el caso total (entradas por tratamiento sin importar el valor de 'simulo')\n",
    "    # Agrupar por 'categoria_clusterizacion_numerica' y 'Tratamiento' para contar el número total de registros en cada combinación.\n",
    "    total_entries_per_cluster_treatment = df_simulaciones_info.groupby(['categoria_clusterizacion_numerica', 'Tratamiento']).size().reset_index(name='caso_total')\n",
    "\n",
    "    # Paso 3: Calcular el caso favorable (entradas por tratamiento cuando 'simulo' == 1)\n",
    "    # Filtrar filas donde 'simulo' es 1 (clientes que realizaron una simulación)\n",
    "    df_simulations = df_simulaciones_info[df_simulaciones_info['simulo'] == 1]\n",
    "\n",
    "    # Agrupar por 'categoria_clusterizacion_numerica' y 'Tratamiento' para contar el número de registros favorables (simulaciones).\n",
    "    favorable_entries_per_cluster_treatment = df_simulations.groupby(['categoria_clusterizacion_numerica', 'Tratamiento']).size().reset_index(name='caso_favorable')\n",
    "\n",
    "    # Paso 4: Calcular la probabilidad de simulación como caso favorable / caso total\n",
    "    # Realizar un merge entre 'total_entries_per_cluster_treatment' y 'favorable_entries_per_cluster_treatment' en las columnas de cluster y tratamiento.\n",
    "    df_probabilities = total_entries_per_cluster_treatment.merge(\n",
    "        favorable_entries_per_cluster_treatment,\n",
    "        on=['categoria_clusterizacion_numerica', 'Tratamiento'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Llenar valores nulos en 'caso_favorable' con 0, asegurando que solo las columnas numéricas estén afectadas.\n",
    "    df_probabilities['caso_favorable'] = df_probabilities['caso_favorable'].fillna(0).astype(int)\n",
    "\n",
    "    # Asegurar que 'caso_total' sea de tipo entero para evitar inconsistencias en los conteos.\n",
    "    df_probabilities['caso_total'] = df_probabilities['caso_total'].astype(int)\n",
    "\n",
    "    # Calcular la probabilidad de simulación como el cociente entre 'caso_favorable' y 'caso_total'.\n",
    "    df_probabilities['probabilidad_simular'] = df_probabilities['caso_favorable'] / df_probabilities['caso_total']\n",
    "\n",
    "    # Organizar las columnas del DataFrame resultante para facilitar su análisis.\n",
    "    df_probabilities = df_probabilities[[\n",
    "        'categoria_clusterizacion_numerica',\n",
    "        'Tratamiento',\n",
    "        'probabilidad_simular',\n",
    "        'caso_favorable',\n",
    "        'caso_total'\n",
    "    ]]\n",
    "\n",
    "    # Mostrar el DataFrame resultante con la probabilidad de simulación calculada para cada combinación de cluster y tratamiento.\n",
    "    return df_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoria_clusterizacion_numerica</th>\n",
       "      <th>Tratamiento</th>\n",
       "      <th>probabilidad_simular</th>\n",
       "      <th>caso_favorable</th>\n",
       "      <th>caso_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=0</td>\n",
       "      <td>0.141104</td>\n",
       "      <td>3231</td>\n",
       "      <td>22898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=1</td>\n",
       "      <td>0.151840</td>\n",
       "      <td>3743</td>\n",
       "      <td>24651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=2</td>\n",
       "      <td>0.161545</td>\n",
       "      <td>3065</td>\n",
       "      <td>18973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>0.169339</td>\n",
       "      <td>8080</td>\n",
       "      <td>47715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Ejecutivo=0, Correos=4</td>\n",
       "      <td>0.172572</td>\n",
       "      <td>13101</td>\n",
       "      <td>75916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>71</td>\n",
       "      <td>Ejecutivo=0, Correos=3</td>\n",
       "      <td>0.174601</td>\n",
       "      <td>7137</td>\n",
       "      <td>40876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>71</td>\n",
       "      <td>Ejecutivo=0, Correos=4</td>\n",
       "      <td>0.178502</td>\n",
       "      <td>11648</td>\n",
       "      <td>65254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>71</td>\n",
       "      <td>Ejecutivo=1, Correos=0</td>\n",
       "      <td>0.338011</td>\n",
       "      <td>2842</td>\n",
       "      <td>8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>71</td>\n",
       "      <td>Ejecutivo=1, Correos=1</td>\n",
       "      <td>0.348168</td>\n",
       "      <td>3231</td>\n",
       "      <td>9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>71</td>\n",
       "      <td>Ejecutivo=1, Correos=2</td>\n",
       "      <td>0.370087</td>\n",
       "      <td>19417</td>\n",
       "      <td>52466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     categoria_clusterizacion_numerica             Tratamiento  \\\n",
       "0                                    0  Ejecutivo=0, Correos=0   \n",
       "1                                    0  Ejecutivo=0, Correos=1   \n",
       "2                                    0  Ejecutivo=0, Correos=2   \n",
       "3                                    0  Ejecutivo=0, Correos=3   \n",
       "4                                    0  Ejecutivo=0, Correos=4   \n",
       "..                                 ...                     ...   \n",
       "571                                 71  Ejecutivo=0, Correos=3   \n",
       "572                                 71  Ejecutivo=0, Correos=4   \n",
       "573                                 71  Ejecutivo=1, Correos=0   \n",
       "574                                 71  Ejecutivo=1, Correos=1   \n",
       "575                                 71  Ejecutivo=1, Correos=2   \n",
       "\n",
       "     probabilidad_simular  caso_favorable  caso_total  \n",
       "0                0.141104            3231       22898  \n",
       "1                0.151840            3743       24651  \n",
       "2                0.161545            3065       18973  \n",
       "3                0.169339            8080       47715  \n",
       "4                0.172572           13101       75916  \n",
       "..                    ...             ...         ...  \n",
       "571              0.174601            7137       40876  \n",
       "572              0.178502           11648       65254  \n",
       "573              0.338011            2842        8408  \n",
       "574              0.348168            3231        9280  \n",
       "575              0.370087           19417       52466  \n",
       "\n",
       "[576 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probabilities = function_estimar_respuesta_a_tratamiento(df1, df2)\n",
    "df_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el DataFrame 'df_estimar_elasticidad' para revisar su contenido antes de realizar cálculos adicionales\n",
    "df_estimar_elasticidad\n",
    "\n",
    "# Calcular el valor promedio de 'Monto_Simulado' para cada 'categoria_clusterizacion_numerica'\n",
    "# Usamos 'groupby' para agrupar por 'categoria_clusterizacion_numerica' y 'transform(\"mean\")' para calcular el promedio.\n",
    "# Luego, 'transform' asigna este valor promedio a cada fila dentro de su grupo, creando una columna 'Monto_Simulado_mean' con estos promedios.\n",
    "df_estimar_elasticidad['Monto_Simulado_mean'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Monto_Simulado'].transform('mean')\n",
    "\n",
    "# Calcular el valor promedio de 'Plazo_Simulado' para cada 'categoria_clusterizacion_numerica'\n",
    "# Similar al cálculo anterior, 'groupby' agrupa los datos por 'categoria_clusterizacion_numerica', y 'transform(\"mean\")' calcula el promedio.\n",
    "# Se asigna el promedio resultante a cada fila dentro del grupo en la nueva columna 'Plazo_Simulado_mean'.\n",
    "df_estimar_elasticidad['Plazo_Simulado_mean'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Plazo_Simulado'].transform('mean')\n",
    "df_estimar_elasticidad['Plazo_Simulado_min'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Plazo_Simulado'].transform('min')\n",
    "df_estimar_elasticidad['Plazo_Simulado_max'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Plazo_Simulado'].transform('max')\n",
    "df_estimar_elasticidad['Plazo_Simulado_mode'] = df_estimar_elasticidad.groupby('categoria_clusterizacion_numerica')['Plazo_Simulado'].transform(lambda x: x.mode().iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas necesarias del DataFrame 'df_estimar_elasticidad' para reducir su tamaño\n",
    "# 'df_estimar_elasticidad_small' contiene las columnas esenciales para el análisis:\n",
    "# 'categoria_clusterizacion_numerica', 'rut', 'tasa_optima', 'probabilidad_aceptacion_optima', 'Probabilidad_No_Pago',\n",
    "# 'Monto_Simulado_mean', y 'Plazo_Simulado_mean'.\n",
    "df_estimar_elasticidad_small = df_estimar_elasticidad[['categoria_clusterizacion_numerica', 'rut', 'tasa_optima', 'probabilidad_aceptacion_optima', 'Probabilidad_No_Pago', \n",
    "                                                       'Monto_Simulado_mean',\n",
    "                                                       'Plazo_Simulado_mean', 'Plazo_Simulado_min', 'Plazo_Simulado_max', 'Plazo_Simulado_mode']]\n",
    "\n",
    "# Seleccionar solo las columnas necesarias del DataFrame 'df_probabilities' para reducir su tamaño\n",
    "# 'df_probabilities_small' contiene las columnas 'categoria_clusterizacion_numerica', 'probabilidad_simular', y 'Tratamiento'.\n",
    "df_probabilities_small = df_probabilities[['categoria_clusterizacion_numerica', 'probabilidad_simular', 'Tratamiento']]\n",
    "\n",
    "# Realizar un merge entre 'df_estimar_elasticidad_small' y 'df_probabilities_small' usando 'categoria_clusterizacion_numerica' como clave\n",
    "# Esta unión ('how=\"left\"') mantiene todas las filas de 'df_estimar_elasticidad_small' y añade la información de 'df_probabilities_small'\n",
    "# cuando hay coincidencias en 'categoria_clusterizacion_numerica'. El resultado se guarda en 'df_asignacion_de_tratamientos'.\n",
    "df_asignacion_de_tratamientos = pd.merge(df_estimar_elasticidad_small, df_probabilities_small, on='categoria_clusterizacion_numerica', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nombre de carpeta con una marca de tiempo actual\n",
    "# 'strftime' genera la fecha y hora actual en el formato \"YYYYMMDD_HHMMSS\".\n",
    "# Esto se usa para crear una carpeta única 'folder_name' donde se guardarán los archivos.\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "folder_name = f\"cluster_data_{timestamp}\"\n",
    "os.makedirs(folder_name, exist_ok=True)  # Crear la carpeta; 'exist_ok=True' evita errores si ya existe.\n",
    "\n",
    "# Guardar información de los clusters\n",
    "# Seleccionar las columnas relevantes sobre cada cluster desde 'df_estimar_elasticidad_small' y eliminar duplicados.\n",
    "# El DataFrame 'df_cluster_info' contiene datos únicos de cada cluster como el monto y plazo medio simulado, la probabilidad de aceptación óptima y la tasa óptima.\n",
    "df_cluster_info = df_estimar_elasticidad_small[['categoria_clusterizacion_numerica', 'probabilidad_aceptacion_optima', 'tasa_optima',\n",
    "                                                'Monto_Simulado_mean',\n",
    "                                                'Plazo_Simulado_mean', 'Plazo_Simulado_min', 'Plazo_Simulado_max', 'Plazo_Simulado_mode']].drop_duplicates()\n",
    "df_cluster_info.to_csv(f\"{folder_name}/cluster_info.csv\", index=False)\n",
    "\n",
    "# Guardar las probabilidades y tratamiento\n",
    "# Seleccionar columnas relevantes de 'df_probabilities_small' para almacenar la probabilidad de simulación y tratamiento asignado para cada cluster.\n",
    "# 'df_probabilities_treatment' contiene esta información única por cada combinación de cluster y tratamiento.\n",
    "df_probabilities_treatment = df_probabilities_small[['categoria_clusterizacion_numerica', 'probabilidad_simular', 'Tratamiento']].drop_duplicates()\n",
    "df_probabilities_treatment.to_csv(f\"{folder_name}/probabilities_treatment.csv\", index=False)\n",
    "\n",
    "# Guardar información del RUT\n",
    "# Seleccionar columnas clave sobre cada cliente ('rut') desde 'df_estimar_elasticidad_small' y eliminar duplicados.\n",
    "# 'df_rut_info' contiene el 'rut', la categoría de cluster y la probabilidad de no pago para cada cliente, sin registros duplicados.\n",
    "df_rut_info = df_estimar_elasticidad_small[['rut', 'categoria_clusterizacion_numerica', 'Probabilidad_No_Pago']].drop_duplicates()\n",
    "df_rut_info.to_csv(f\"{folder_name}/rut_info.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modelo de asignacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de asignacion que itera por cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_optimizacion(df_probabilities_treatment, df_rut_info, df_cluster_info, costo_sms, ejecutivos):\n",
    "    # -------------------------------\n",
    "    # Procesamiento y preprocesamiento de datos\n",
    "    # -------------------------------\n",
    "\n",
    "    # Definir la carpeta base y el mapeo de tratamientos\n",
    "    tratamiento_map = {  # Mapeo de los tratamientos específicos a identificadores numéricos\n",
    "        \"Ejecutivo=0, Correos=0\": 1, \"Ejecutivo=0, Correos=1\": 2,\n",
    "        \"Ejecutivo=0, Correos=2\": 3, \"Ejecutivo=0, Correos=3\": 4,\n",
    "        \"Ejecutivo=0, Correos=4\": 5, \"Ejecutivo=1, Correos=0\": 6,\n",
    "        \"Ejecutivo=1, Correos=1\": 7, \"Ejecutivo=1, Correos=2\": 8\n",
    "    }\n",
    "\n",
    "    # Parámetros\n",
    "    costosms = costo_sms # Costo de cada mensaje SMS\n",
    "    capacidad_ejecutivos = ejecutivos  # Capacidad máxima en términos de tiempo de los ejecutivos\n",
    "\n",
    "    # Paso 1: Cargar y mapear 'tratamiento_id' en los datos de probabilidades\n",
    "    print(\"Loading and processing probabilities data...\")\n",
    "    df_probabilities = df_probabilities_treatment\n",
    "    df_probabilities['tratamiento_id'] = df_probabilities['Tratamiento'].map(tratamiento_map)\n",
    "\n",
    "    # Paso 2: Crear lista de tratamientos y combinar con rut_info\n",
    "    print(\"Merging probabilities with rut_info...\")\n",
    "    df_probabilities['tratamientos'] = df_probabilities[['probabilidad_simular', 'tratamiento_id']].values.tolist()\n",
    "    grouped_prob = df_probabilities.groupby('categoria_clusterizacion_numerica')['tratamientos'].apply(list).reset_index()\n",
    "\n",
    "\n",
    "    df_rut_info1 = df_rut_info.merge(grouped_prob, on='categoria_clusterizacion_numerica', how='left')\n",
    "\n",
    "\n",
    "    # Paso 3: Combinar rut_info con cluster_info\n",
    "    print(\"Merging rut_info with cluster_info...\")\n",
    "    df_cluster_info = df_cluster_info\n",
    "    df_rut_info2 = df_rut_info1.merge(df_cluster_info, on='categoria_clusterizacion_numerica', how='left')\n",
    "\n",
    "    # Paso 3.5: Agrupar información por cluster en 'rut_info'\n",
    "    # Agrupar por 'categoria_clusterizacion_numerica' y agregar según lo especificado\n",
    "    df_grouped = df_rut_info2.groupby('categoria_clusterizacion_numerica').agg({\n",
    "        'Probabilidad_No_Pago': 'mean',  # Promedio de probabilidad de no pago\n",
    "        'tratamientos': lambda x: list(x),  # Lista de opciones de tratamiento únicas en cada cluster\n",
    "        'Monto_Simulado_mean': 'mean',\n",
    "        'Plazo_Simulado_mean': 'mean',\n",
    "        'probabilidad_aceptacion_optima': 'mean',\n",
    "        'tasa_optima': 'mean',\n",
    "        'rut': 'count'  # Conteo del número de clientes ('rut') en cada cluster\n",
    "    }).rename(columns={'rut': 'n_clientes'}).reset_index()\n",
    "\n",
    "    # Paso 4: Calcular 'RC' (Revenue calculado)\n",
    "    print(\"Calculating RC...\")\n",
    "    df_grouped['tasa_optima'] /= 100  # Convertir tasa óptima a decimal\n",
    "    df_grouped['RC'] = (\n",
    "        (df_grouped['Plazo_Simulado_mean'] * df_grouped['Monto_Simulado_mean'] * df_grouped['tasa_optima'] *\n",
    "        ((1 + df_grouped['tasa_optima']) ** df_grouped['Plazo_Simulado_mean'])) /\n",
    "        (((1 + df_grouped['tasa_optima']) ** df_grouped['Plazo_Simulado_mean']) - 1)\n",
    "    ) - df_grouped['Monto_Simulado_mean']\n",
    "\n",
    "    # -------------------------------\n",
    "    # Preparación de datos para optimización\n",
    "    # -------------------------------\n",
    "\n",
    "    # Convertir 'tratamientos' a un arreglo de numpy para mejorar la indexación\n",
    "    # Desarrollar y preparar 'tratamientos' para indexación adecuada\n",
    "    profits = np.array([\n",
    "        [\n",
    "            row['n_clientes'] * (row['RC'] * (1 - row['Probabilidad_No_Pago']) * row['probabilidad_aceptacion_optima'] * row['tratamientos'][0][t][0]) - \n",
    "            (row['tratamientos'][0][t][1] * costosms)\n",
    "            for t in range(8)\n",
    "        ]\n",
    "        for _, row in df_grouped.iterrows()\n",
    "    ])\n",
    "\n",
    "    # Inicializar el modelo de optimización\n",
    "    model = Model(\"Maximizar_Ganancias\")\n",
    "    model.ModelSense = GRB.MAXIMIZE\n",
    "\n",
    "    # Crear variables de decisión y definir el objetivo\n",
    "    n_clients, n_treatments = profits.shape\n",
    "    variables = {}\n",
    "\n",
    "    for i in range(n_clients):\n",
    "        variables[i] = {}\n",
    "        for t in range(n_treatments):\n",
    "            if profits[i, t] > 0:\n",
    "                variables[i][t] = model.addVar(vtype=GRB.BINARY, name=f\"x_{i}_{t}\")\n",
    "\n",
    "    model.setObjective(\n",
    "        quicksum(variables[i][t] * profits[i, t] for i in variables for t in variables[i])\n",
    "    )\n",
    "\n",
    "    # Restricción: Cada cliente recibe exactamente un tratamiento\n",
    "    for i in variables:\n",
    "        model.addConstr(quicksum(variables[i].values()) == 1, name=f\"OneTreatmentPerClient_{i}\")\n",
    "\n",
    "    # Restricción de capacidad para ejecutivos\n",
    "    model.addConstr(\n",
    "        quicksum(variables[i][t] * df_grouped.loc[i, 'n_clientes'] for i in variables for t in variables[i] if t in [5, 6, 7]) <= capacidad_ejecutivos,\n",
    "        name=\"CapacityConstraint\"\n",
    "    )\n",
    "\n",
    "    # Consistencia de cluster: los clientes dentro del mismo cluster deben recibir el mismo tratamiento\n",
    "    clusters = df_grouped.groupby(\"categoria_clusterizacion_numerica\").indices\n",
    "    for cluster_id, indices_cluster in clusters.items():\n",
    "        indices_list = list(indices_cluster)\n",
    "        leader_index = indices_list[0]\n",
    "        for t in variables[leader_index]:\n",
    "            leader_var = variables[leader_index][t]\n",
    "            for i in indices_list[1:]:\n",
    "                if t in variables[i]:\n",
    "                    model.addConstr(variables[i][t] == leader_var, name=f\"ClusterConsistency_{cluster_id}_{t}\")\n",
    "\n",
    "    # Optimizar el modelo\n",
    "    model.optimize()\n",
    "\n",
    "    # Verificar si la optimización fue exitosa\n",
    "    if model.Status == GRB.OPTIMAL:\n",
    "        # -------------------------------\n",
    "        # Extracción y visualización de resultados\n",
    "        # -------------------------------\n",
    "\n",
    "        print(\"Extracting results...\")\n",
    "\n",
    "        # Asignar tratamientos por cluster basado en los resultados de la optimización\n",
    "        resultados_por_cluster = {}\n",
    "        for cluster_id, indices_cluster in clusters.items():\n",
    "            leader_index = list(indices_cluster)[0]\n",
    "            for t in variables[leader_index]:\n",
    "                if variables[leader_index][t].X > 0.5:\n",
    "                    resultados_por_cluster[cluster_id] = t + 1\n",
    "                    break\n",
    "\n",
    "        # Calcular las ganancias totales\n",
    "        ganancias_totales = model.ObjVal\n",
    "\n",
    "        # Mostrar resultados\n",
    "        print(\"\\nTratamientos asignados por cluster:\")\n",
    "        for cluster_id, tratamiento in resultados_por_cluster.items():\n",
    "            print(f\"Cluster {cluster_id}: Tratamiento {tratamiento}\")\n",
    "\n",
    "        print(f\"\\nGanancias totales: {ganancias_totales:.2f}\")\n",
    "\n",
    "        # Calcular el número de ejecutivos usados y restantes\n",
    "        executives_used = sum(\n",
    "            df_grouped.loc[i, 'n_clientes'] for i in variables for t in variables[i]\n",
    "            if t in [5, 6, 7] and variables[i][t].X > 0.5\n",
    "        )\n",
    "        executives_remaining = capacidad_ejecutivos - executives_used\n",
    "\n",
    "        # Mostrar resumen de uso de ejecutivos\n",
    "        print(f\"\\nExecutives used: {executives_used}\")\n",
    "        print(f\"Executives remaining: {executives_remaining}\")\n",
    "    else:\n",
    "        print(\"Optimization did not reach an optimal solution.\")\n",
    "    print(\"Optimization complete.\")\n",
    "    return ganancias_totales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing probabilities data...\n",
      "Merging probabilities with rut_info...\n",
      "Merging rut_info with cluster_info...\n",
      "Calculating RC...\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-11-06\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: AMD Ryzen 5 2500U with Radeon Vega Mobile Gfx, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 73 rows, 576 columns and 792 nonzeros\n",
      "Model fingerprint: 0x5ff5821b\n",
      "Variable types: 0 continuous, 576 integer (576 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+04]\n",
      "  Objective range  [5e+06, 3e+10]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+05]\n",
      "Warning: Model contains large objective coefficients\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 6.234389e+10\n",
      "Presolve removed 72 rows and 504 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 1 rows, 72 columns, 72 nonzeros\n",
      "Found heuristic solution: objective 1.244267e+11\n",
      "Variable types: 0 continuous, 72 integer (72 binary)\n",
      "Found heuristic solution: objective 1.245683e+11\n",
      "\n",
      "Root relaxation: objective 1.458340e+11, 1 iterations, 0.01 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.4583e+11    0    1 1.2457e+11 1.4583e+11  17.1%     -    0s\n",
      "H    0     0                    1.331174e+11 1.4583e+11  9.55%     -    0s\n",
      "H    0     0                    1.455788e+11 1.4583e+11  0.18%     -    0s\n",
      "H    0     0                    1.456425e+11 1.4583e+11  0.13%     -    0s\n",
      "     0     0 1.4571e+11    0    1 1.4564e+11 1.4571e+11  0.05%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  MIR: 1\n",
      "\n",
      "Explored 1 nodes (2 simplex iterations) in 0.87 seconds (0.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 6: 1.45642e+11 1.45579e+11 1.33117e+11 ... 6.23439e+10\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.456424700385e+11, best bound 1.456424700385e+11, gap 0.0000%\n",
      "Extracting results...\n",
      "\n",
      "Tratamientos asignados por cluster:\n",
      "Cluster 0: Tratamiento 8\n",
      "Cluster 1: Tratamiento 8\n",
      "Cluster 2: Tratamiento 5\n",
      "Cluster 3: Tratamiento 5\n",
      "Cluster 4: Tratamiento 5\n",
      "Cluster 5: Tratamiento 5\n",
      "Cluster 6: Tratamiento 8\n",
      "Cluster 7: Tratamiento 8\n",
      "Cluster 8: Tratamiento 5\n",
      "Cluster 9: Tratamiento 5\n",
      "Cluster 10: Tratamiento 5\n",
      "Cluster 11: Tratamiento 5\n",
      "Cluster 12: Tratamiento 5\n",
      "Cluster 13: Tratamiento 5\n",
      "Cluster 14: Tratamiento 4\n",
      "Cluster 15: Tratamiento 5\n",
      "Cluster 16: Tratamiento 5\n",
      "Cluster 17: Tratamiento 5\n",
      "Cluster 18: Tratamiento 5\n",
      "Cluster 19: Tratamiento 5\n",
      "Cluster 20: Tratamiento 5\n",
      "Cluster 21: Tratamiento 5\n",
      "Cluster 22: Tratamiento 5\n",
      "Cluster 23: Tratamiento 5\n",
      "Cluster 24: Tratamiento 8\n",
      "Cluster 25: Tratamiento 8\n",
      "Cluster 26: Tratamiento 5\n",
      "Cluster 27: Tratamiento 5\n",
      "Cluster 28: Tratamiento 5\n",
      "Cluster 29: Tratamiento 5\n",
      "Cluster 30: Tratamiento 8\n",
      "Cluster 31: Tratamiento 8\n",
      "Cluster 32: Tratamiento 5\n",
      "Cluster 33: Tratamiento 5\n",
      "Cluster 34: Tratamiento 5\n",
      "Cluster 35: Tratamiento 5\n",
      "Cluster 36: Tratamiento 8\n",
      "Cluster 37: Tratamiento 8\n",
      "Cluster 38: Tratamiento 4\n",
      "Cluster 39: Tratamiento 5\n",
      "Cluster 40: Tratamiento 5\n",
      "Cluster 41: Tratamiento 5\n",
      "Cluster 42: Tratamiento 5\n",
      "Cluster 43: Tratamiento 5\n",
      "Cluster 44: Tratamiento 5\n",
      "Cluster 45: Tratamiento 5\n",
      "Cluster 46: Tratamiento 5\n",
      "Cluster 47: Tratamiento 4\n",
      "Cluster 48: Tratamiento 8\n",
      "Cluster 49: Tratamiento 5\n",
      "Cluster 50: Tratamiento 5\n",
      "Cluster 51: Tratamiento 5\n",
      "Cluster 52: Tratamiento 5\n",
      "Cluster 53: Tratamiento 5\n",
      "Cluster 54: Tratamiento 8\n",
      "Cluster 55: Tratamiento 8\n",
      "Cluster 56: Tratamiento 5\n",
      "Cluster 57: Tratamiento 5\n",
      "Cluster 58: Tratamiento 4\n",
      "Cluster 59: Tratamiento 5\n",
      "Cluster 60: Tratamiento 5\n",
      "Cluster 61: Tratamiento 4\n",
      "Cluster 62: Tratamiento 5\n",
      "Cluster 63: Tratamiento 5\n",
      "Cluster 64: Tratamiento 5\n",
      "Cluster 65: Tratamiento 5\n",
      "Cluster 66: Tratamiento 4\n",
      "Cluster 67: Tratamiento 5\n",
      "Cluster 68: Tratamiento 5\n",
      "Cluster 69: Tratamiento 5\n",
      "Cluster 70: Tratamiento 4\n",
      "Cluster 71: Tratamiento 5\n",
      "\n",
      "Ganancias totales: 145642470038.49\n",
      "\n",
      "Executives used: 204542\n",
      "Executives remaining: 458\n",
      "Optimization complete.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Procesamiento y preprocesamiento de datos\n",
    "# -------------------------------\n",
    "# Definir la carpeta base y el mapeo de tratamientos\n",
    "tratamiento_map = {  # Mapeo de los tratamientos específicos a identificadores numéricos\n",
    "    \"Ejecutivo=0, Correos=0\": 1, \"Ejecutivo=0, Correos=1\": 2,\n",
    "    \"Ejecutivo=0, Correos=2\": 3, \"Ejecutivo=0, Correos=3\": 4,\n",
    "    \"Ejecutivo=0, Correos=4\": 5, \"Ejecutivo=1, Correos=0\": 6,\n",
    "    \"Ejecutivo=1, Correos=1\": 7, \"Ejecutivo=1, Correos=2\": 8\n",
    "}\n",
    "# Parámetros\n",
    "costosms = 100 # Costo de cada mensaje SMS\n",
    "capacidad_ejecutivos = 205000  # Capacidad máxima en términos de tiempo de los ejecutivos\n",
    "# Paso 1: Cargar y mapear 'tratamiento_id' en los datos de probabilidades\n",
    "print(\"Loading and processing probabilities data...\")\n",
    "df_probabilities = df_probabilities_treatment\n",
    "df_probabilities['tratamiento_id'] = df_probabilities['Tratamiento'].map(tratamiento_map)\n",
    "# Paso 2: Crear lista de tratamientos y combinar con rut_info\n",
    "print(\"Merging probabilities with rut_info...\")\n",
    "df_probabilities['tratamientos'] = df_probabilities[['probabilidad_simular', 'tratamiento_id']].values.tolist()\n",
    "grouped_prob = df_probabilities.groupby('categoria_clusterizacion_numerica')['tratamientos'].apply(list).reset_index()\n",
    "df_rut_info1 = df_rut_info.merge(grouped_prob, on='categoria_clusterizacion_numerica', how='left')\n",
    "# Paso 3: Combinar rut_info con cluster_info\n",
    "print(\"Merging rut_info with cluster_info...\")\n",
    "df_cluster_info = df_cluster_info\n",
    "df_rut_info2 = df_rut_info1.merge(df_cluster_info, on='categoria_clusterizacion_numerica', how='left')\n",
    "# Paso 3.5: Agrupar información por cluster en 'rut_info'\n",
    "# Agrupar por 'categoria_clusterizacion_numerica' y agregar según lo especificado\n",
    "df_grouped = df_rut_info2.groupby('categoria_clusterizacion_numerica').agg({\n",
    "    'Probabilidad_No_Pago': 'mean',  # Promedio de probabilidad de no pago\n",
    "    'tratamientos': lambda x: list(x),  # Lista de opciones de tratamiento únicas en cada cluster\n",
    "    'Monto_Simulado_mean': 'mean',\n",
    "    'Plazo_Simulado_mean': 'mean',\n",
    "    'probabilidad_aceptacion_optima': 'mean',\n",
    "    'tasa_optima': 'mean',\n",
    "    'rut': 'count'  # Conteo del número de clientes ('rut') en cada cluster\n",
    "}).rename(columns={'rut': 'n_clientes'}).reset_index()\n",
    "# Paso 4: Calcular 'RC' (Revenue calculado)\n",
    "print(\"Calculating RC...\")\n",
    "df_grouped['tasa_optima'] /= 100  # Convertir tasa óptima a decimal\n",
    "df_grouped['RC'] = (\n",
    "    (df_grouped['Plazo_Simulado_mean'] * df_grouped['Monto_Simulado_mean'] * df_grouped['tasa_optima'] *\n",
    "    ((1 + df_grouped['tasa_optima']) ** df_grouped['Plazo_Simulado_mean'])) /\n",
    "    (((1 + df_grouped['tasa_optima']) ** df_grouped['Plazo_Simulado_mean']) - 1)\n",
    ") - df_grouped['Monto_Simulado_mean']\n",
    "# -------------------------------\n",
    "# Preparación de datos para optimización\n",
    "# -------------------------------\n",
    "# Convertir 'tratamientos' a un arreglo de numpy para mejorar la indexación\n",
    "# Desarrollar y preparar 'tratamientos' para indexación adecuada\n",
    "profits = np.array([\n",
    "    [\n",
    "        row['n_clientes'] * (row['RC'] * (1 - row['Probabilidad_No_Pago']) * row['probabilidad_aceptacion_optima'] * row['tratamientos'][0][t][0]) - \n",
    "        (row['tratamientos'][0][t][1] * costosms)\n",
    "        for t in range(8)\n",
    "    ]\n",
    "    for _, row in df_grouped.iterrows()\n",
    "])\n",
    "# Inicializar el modelo de optimización\n",
    "model = Model(\"Maximizar_Ganancias\")\n",
    "model.ModelSense = GRB.MAXIMIZE\n",
    "# Crear variables de decisión y definir el objetivo\n",
    "n_clients, n_treatments = profits.shape\n",
    "variables = {}\n",
    "for i in range(n_clients):\n",
    "    variables[i] = {}\n",
    "    for t in range(n_treatments):\n",
    "        if profits[i, t] > 0:\n",
    "            variables[i][t] = model.addVar(vtype=GRB.BINARY, name=f\"x_{i}_{t}\")\n",
    "model.setObjective(\n",
    "    quicksum(variables[i][t] * profits[i, t] for i in variables for t in variables[i])\n",
    ")\n",
    "# Restricción: Cada cliente recibe exactamente un tratamiento\n",
    "for i in variables:\n",
    "    model.addConstr(quicksum(variables[i].values()) == 1, name=f\"OneTreatmentPerClient_{i}\")\n",
    "# Restricción de capacidad para ejecutivos\n",
    "model.addConstr(\n",
    "    quicksum(variables[i][t] * df_grouped.loc[i, 'n_clientes'] for i in variables for t in variables[i] if t in [5, 6, 7]) <= capacidad_ejecutivos,\n",
    "    name=\"CapacityConstraint\"\n",
    ")\n",
    "# Consistencia de cluster: los clientes dentro del mismo cluster deben recibir el mismo tratamiento\n",
    "clusters = df_grouped.groupby(\"categoria_clusterizacion_numerica\").indices\n",
    "for cluster_id, indices_cluster in clusters.items():\n",
    "    indices_list = list(indices_cluster)\n",
    "    leader_index = indices_list[0]\n",
    "    for t in variables[leader_index]:\n",
    "        leader_var = variables[leader_index][t]\n",
    "        for i in indices_list[1:]:\n",
    "            if t in variables[i]:\n",
    "                model.addConstr(variables[i][t] == leader_var, name=f\"ClusterConsistency_{cluster_id}_{t}\")\n",
    "# Optimizar el modelo\n",
    "model.optimize()\n",
    "# Verificar si la optimización fue exitosa\n",
    "if model.Status == GRB.OPTIMAL:\n",
    "    # -------------------------------\n",
    "    # Extracción y visualización de resultados\n",
    "    # -------------------------------\n",
    "    print(\"Extracting results...\")\n",
    "    # Asignar tratamientos por cluster basado en los resultados de la optimización\n",
    "    resultados_por_cluster = {}\n",
    "    for cluster_id, indices_cluster in clusters.items():\n",
    "        leader_index = list(indices_cluster)[0]\n",
    "        for t in variables[leader_index]:\n",
    "            if variables[leader_index][t].X > 0.5:\n",
    "                resultados_por_cluster[cluster_id] = t + 1\n",
    "                break\n",
    "    # Calcular las ganancias totales\n",
    "    ganancias_totales = model.ObjVal\n",
    "    # Mostrar resultados\n",
    "    print(\"\\nTratamientos asignados por cluster:\")\n",
    "    for cluster_id, tratamiento in resultados_por_cluster.items():\n",
    "        print(f\"Cluster {cluster_id}: Tratamiento {tratamiento}\")\n",
    "    print(f\"\\nGanancias totales: {ganancias_totales:.2f}\")\n",
    "    # Calcular el número de ejecutivos usados y restantes\n",
    "    executives_used = sum(\n",
    "        df_grouped.loc[i, 'n_clientes'] for i in variables for t in variables[i]\n",
    "        if t in [5, 6, 7] and variables[i][t].X > 0.5\n",
    "    )\n",
    "    executives_remaining = capacidad_ejecutivos - executives_used\n",
    "    # Mostrar resumen de uso de ejecutivos\n",
    "    print(f\"\\nExecutives used: {executives_used}\")\n",
    "    print(f\"Executives remaining: {executives_remaining}\")\n",
    "else:\n",
    "    print(\"Optimization did not reach an optimal solution.\")\n",
    "print(\"Optimization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment 8: 13 times\n",
      "Treatment 5: 52 times\n",
      "Treatment 4: 7 times\n"
     ]
    }
   ],
   "source": [
    "# Contar cuántas veces se asigna cada tratamiento en los resultados por cluster\n",
    "# Se utiliza un diccionario 'Counter' para contar las ocurrencias de cada tratamiento asignado en 'resultados_por_cluster'\n",
    "for cluster_id, tratamiento in resultados_por_cluster.items():\n",
    "    treatment_counts = Counter(resultados_por_cluster.values())\n",
    "\n",
    "# Imprimir el conteo de asignaciones para cada tratamiento\n",
    "# Se recorre 'treatment_counts' para mostrar cuántas veces se asignó cada tratamiento.\n",
    "# 'treatment + 1' se utiliza para mostrar el número de tratamiento en base 1, haciendo el resultado más legible.\n",
    "for treatment, count in treatment_counts.items():\n",
    "    print(f\"Treatment {treatment}: {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>assigned_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster  assigned_treatment\n",
       "0         0                   8\n",
       "1         1                   8\n",
       "2         2                   5\n",
       "3         3                   5\n",
       "4         4                   5\n",
       "..      ...                 ...\n",
       "67       67                   5\n",
       "68       68                   5\n",
       "69       69                   5\n",
       "70       70                   4\n",
       "71       71                   5\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir el diccionario 'resultados_por_cluster' a un DataFrame\n",
    "# El diccionario 'resultados_por_cluster' contiene el ID del cluster y el tratamiento asignado a cada uno.\n",
    "# Se convierte a un DataFrame donde la primera columna es 'cluster' y la segunda 'assigned_treatment'.\n",
    "df_resultados_por_cluster = pd.DataFrame(list(resultados_por_cluster.items()), columns=[\"cluster\", \"assigned_treatment\"])\n",
    "\n",
    "# Mostrar el DataFrame resultante al usuario\n",
    "df_resultados_por_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer merge con 'df_rut_info'\n",
    "# Realizar una unión ('merge') entre 'df_resultados_por_cluster' y 'df_rut_info' usando 'cluster' en el primer DataFrame\n",
    "# y 'categoria_clusterizacion_numerica' en el segundo como claves de unión.\n",
    "# Esta unión permite agregar información de clientes a cada cluster con su tratamiento asignado.\n",
    "df_assigned = pd.merge(df_resultados_por_cluster, df_rut_info2, left_on='cluster', right_on='categoria_clusterizacion_numerica', how='left')\n",
    "\n",
    "# Segundo merge con 'df_grouped' para agregar la columna 'RC'\n",
    "# Realizar una unión entre 'df_assigned' y 'df_grouped' para incorporar la columna 'RC' (Revenue Calculado)\n",
    "# Usamos 'categoria_clusterizacion_numerica' como clave de unión para añadir la información de revenue calculado a cada cluster.\n",
    "df_assigned = pd.merge(df_assigned, df_grouped[['categoria_clusterizacion_numerica', 'RC']], on='categoria_clusterizacion_numerica', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la probabilidad de simulación para el tratamiento asignado en cada fila de 'df_assigned'\n",
    "# Se usa 'apply' con una función lambda para extraer la probabilidad de simulación correspondiente al tratamiento asignado.\n",
    "# 'row['tratamientos']' es una lista de opciones de tratamiento y 'row['assigned_treatment'] - 1' indica la posición del tratamiento.\n",
    "# Primero, se verifica que 'tratamientos' sea una lista y que el índice calculado esté dentro del rango.\n",
    "# Si estas condiciones se cumplen, se extrae la probabilidad de simulación; en caso contrario, se asigna None.\n",
    "df_assigned['probabilidad_de_simular'] = df_assigned.apply(\n",
    "    lambda row: row['tratamientos'][row['assigned_treatment'] - 1][0] \n",
    "                if isinstance(row['tratamientos'], list) and (0 <= row['assigned_treatment'] - 1 < len(row['tratamientos'])) \n",
    "                else None,\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved in folder: assigned_treatments/assignation_20250617_113849\\assigned_treatments.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear una carpeta con un nombre basado en la fecha y hora actual\n",
    "# 'strftime' genera un timestamp en el formato \"YYYYMMDD_HHMMSS\" para asegurar nombres de carpeta únicos.\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "folder_name = f\"assigned_treatments/assignation_{timestamp}\"\n",
    "os.makedirs(folder_name, exist_ok=True)  # Crear la carpeta; 'exist_ok=True' evita errores si la carpeta ya existe.\n",
    "\n",
    "# Definir la ruta del archivo CSV dentro de la nueva carpeta\n",
    "output_path = os.path.join(folder_name, 'assigned_treatments.csv')\n",
    "\n",
    "# Guardar el DataFrame 'df_assigned' con las columnas seleccionadas en un archivo CSV\n",
    "# Se incluyen las columnas clave: 'rut', 'cluster', 'Probabilidad_No_Pago', 'RC', 'assigned_treatment',\n",
    "# 'probabilidad_de_simular', 'tasa_optima' y 'probabilidad_aceptacion_optima'.\n",
    "df_assigned[['rut', 'cluster', 'Probabilidad_No_Pago', 'RC', 'assigned_treatment', 'probabilidad_de_simular', 'tasa_optima', 'probabilidad_aceptacion_optima']].to_csv(output_path, index=False)\n",
    "\n",
    "# Imprimir mensaje de confirmación con la ubicación del archivo CSV guardado\n",
    "print(f\"CSV file saved in folder: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicion de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración básica del logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Nivel de logging (puede ser DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Mostrar logs en la consola\n",
    "        # Puedes agregar FileHandler para guardar logs en un archivo si lo deseas\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)  # Crear un logger\n",
    "\n",
    "# Definir la clase ClusteringEnv\n",
    "class ClusteringEnv(gym.Env):\n",
    "    def __init__(self, data, df_sim_ventas_tratamiento, df_simulaciones_info, cluster_limit: int = 25):\n",
    "        super(ClusteringEnv, self).__init__()\n",
    "        logger.info(\"Inicializando ClusteringEnv con límite de clusters: %d...\", cluster_limit)\n",
    "\n",
    "        # Parámetros de simulación\n",
    "        self.data = data\n",
    "        self.df_sim_ventas_tratamiento = df_sim_ventas_tratamiento\n",
    "        self.df_simulaciones_info = df_simulaciones_info\n",
    "        self.cluster_limit = cluster_limit  # Límite máximo de clusters permitido por episodio\n",
    "\n",
    "        # Inicializar mejores métricas\n",
    "        self.best_reward = float('-inf')\n",
    "        self.best_revenue = float('-inf')\n",
    "\n",
    "        # Variables disponibles (excluyendo 'rut' si existe)\n",
    "        self.variables = [c for c in self.data.columns if c != 'rut']\n",
    "        logger.debug(f\"Variables disponibles: {self.variables}\")\n",
    "\n",
    "        # Identificar variables categóricas y continuas\n",
    "        self.categorical_vars = self.data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        self.continuous_vars = [c for c in self.data.select_dtypes(include=[np.number]).columns if c != 'rut']\n",
    "        logger.info(f\"Variables categóricas: {self.categorical_vars}\")\n",
    "        logger.info(f\"Variables continuas: {self.continuous_vars}\")\n",
    "\n",
    "        # Parámetros de splits para continuas (min 2, max 3)\n",
    "        self.min_splits = 2\n",
    "        self.max_splits = 3\n",
    "        logger.info(f\"Cortes permitidos por variable continua: entre {self.min_splits} y {self.max_splits}.\")\n",
    "\n",
    "        # Crear acciones posibles\n",
    "        self.action_list = self.create_action_list()\n",
    "        logger.info(f\"Número de acciones posibles: {len(self.action_list)}\")\n",
    "\n",
    "        # Definir espacios de Gym\n",
    "        self.action_space = spaces.Discrete(len(self.action_list))\n",
    "        state_size = self._compute_state_size()\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(state_size,), dtype=np.float32)\n",
    "        logger.debug(f\"Dimensión del estado: {state_size}\")\n",
    "\n",
    "        # Contadores de episodio\n",
    "        self.current_step = 0\n",
    "        self.max_steps = 20  # tope de acciones por episodio\n",
    "\n",
    "        # Inicializar estado\n",
    "        self.reset()\n",
    "\n",
    "    def _compute_state_size(self):\n",
    "        # Cada variable: 1 indicador de inclusión + max_splits valores si continua\n",
    "        n_vars = len(self.variables)\n",
    "        return n_vars + len(self.continuous_vars) * self.max_splits\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        logger.info(\"Reiniciando el entorno al estado inicial...\")\n",
    "        # Estado previo: no hay variables incluidas, no hay splits\n",
    "        self.included_vars = {var: 0 for var in self.variables}\n",
    "        self.splits = {var: [] for var in self.continuous_vars}\n",
    "        self.current_step = 0\n",
    "        # Reconstruir el estado\n",
    "        self.state = self.get_state()\n",
    "        # Limpiar histórico de mejores métricas si quisieras\n",
    "        # self.best_reward = float('-inf')\n",
    "        # self.best_revenue = float('-inf')\n",
    "        return self.state, {}\n",
    "    \n",
    "    def get_state(self):\n",
    "        # Construye el vector de estado:\n",
    "        # - Para cada variable: indicador de inclusión (0/1)\n",
    "        # - Para variables continuas: valores normalizados de splits (padded a max_splits)\n",
    "        state = []\n",
    "        # Precalcular mínimos y máximos para normalización\n",
    "        min_max = {var: (self.data[var].min(), self.data[var].max()) for var in self.continuous_vars}\n",
    "\n",
    "        for var in self.variables:\n",
    "            included = self.included_vars[var]\n",
    "            state.append(included)\n",
    "\n",
    "            if var in self.continuous_vars:\n",
    "                min_val, max_val = min_max[var]\n",
    "                if included and self.splits[var] and max_val > min_val:\n",
    "                    splits = sorted(self.splits[var])\n",
    "                    normalized = [(s - min_val) / (max_val - min_val) for s in splits]\n",
    "                    # Rellenar con ceros hasta max_splits\n",
    "                    normalized += [0] * (self.max_splits - len(normalized))\n",
    "                    normalized = normalized[:self.max_splits]\n",
    "                else:\n",
    "                    # No incluido o sin splits => ceros\n",
    "                    normalized = [0] * self.max_splits\n",
    "                state.extend(normalized)\n",
    "\n",
    "        return np.array(state, dtype=np.float32)\n",
    "    \n",
    "    def create_action_list(self):\n",
    "        \"\"\"\n",
    "        Genera la lista de acciones posibles para el agente:\n",
    "        - toggle_variable: incluir o excluir cualquier variable.\n",
    "        - adjust_splits: increase, decrease o move (por índice y cantidad) cortes en variables continuas.\n",
    "        \"\"\"\n",
    "        actions = []\n",
    "        # Acciones toggle para todas las variables\n",
    "        for var in self.variables:\n",
    "            actions.append(('toggle_variable', var, {}))\n",
    "\n",
    "        # Acciones de ajuste de splits solo para variables continuas\n",
    "        for var in self.continuous_vars:\n",
    "            # Aumentar o disminuir número de cortes\n",
    "            actions.extend([\n",
    "                ('adjust_splits', var, {'operation': 'increase'}),\n",
    "                ('adjust_splits', var, {'operation': 'decrease'})\n",
    "            ])\n",
    "            # Mover cada posible índice de split hacia arriba o abajo\n",
    "            for idx in range(self.max_splits):\n",
    "                actions.append(('adjust_splits', var, {'operation': 'move', 'index': idx, 'amount': +1}))\n",
    "                actions.append(('adjust_splits', var, {'operation': 'move', 'index': idx, 'amount': -1}))\n",
    "\n",
    "        logger.debug(f\"Acciones generadas: {actions}\")\n",
    "        return actions\n",
    "    \n",
    "    def step(self, action_index):\n",
    "        \"\"\"\n",
    "        1) Proyecta cuántos clusters resultarán de la acción, sin clustering completo;\n",
    "        2) Si excede cluster_limit, descarta acción (reward=0);\n",
    "        3) Si es viable, aplica acción, calcula reward=total_revenue;\n",
    "        4) Actualiza métricas, avanza estado y retorna.\n",
    "        \"\"\"\n",
    "        action = self.action_list[action_index]\n",
    "        logger.debug(f\"Intentando acción: {action}\")\n",
    "\n",
    "        # Copia temporal de estado para proyección\n",
    "        temp_included = self.included_vars.copy()\n",
    "        temp_splits = {v: self.splits[v].copy() for v in self.splits}\n",
    "        # Simular toggle o ajuste de splits\n",
    "        self.included_vars, self.splits = temp_included, temp_splits\n",
    "        self.apply_action(action)\n",
    "\n",
    "        # Calcular número estimado de clusters sin clustering real:\n",
    "        est_clusters = 1\n",
    "        for var, inc in self.included_vars.items():\n",
    "            if not inc:\n",
    "                continue\n",
    "            if var in self.categorical_vars:\n",
    "                # todas las categorías cuentan como grupos\n",
    "                est_clusters *= self.data[var].nunique()\n",
    "            else:\n",
    "                # número de bins = splits+1\n",
    "                est_clusters *= (len(self.splits[var]) + 1)\n",
    "\n",
    "        # Restaurar estado real\n",
    "        self.included_vars = temp_included\n",
    "        self.splits = temp_splits\n",
    "\n",
    "        # Verificar límite de clusters\n",
    "        if est_clusters > self.cluster_limit:\n",
    "            logger.warning(f\"Acción inviable: est_clusters ({est_clusters}) > límite ({self.cluster_limit}). Descarta.\")\n",
    "            return self.state, 0.0, False, False, {'est_clusters': est_clusters, 'violated_limit': True}\n",
    "\n",
    "        # Acción viable: aplicar y proceder\n",
    "        self.apply_action(action)\n",
    "        df = self.perform_clustering()\n",
    "        total_revenue, num_clusters = self.recalculate_metrics(df)\n",
    "\n",
    "        # Recompensa directa\n",
    "        reward = total_revenue\n",
    "        logger.info(f\"Reward (revenue): {reward}, Clusters reales: {num_clusters}\")\n",
    "\n",
    "        # Actualizar mejor configuración\n",
    "        if reward > self.best_reward:\n",
    "            self.best_reward = reward\n",
    "            self.best_revenue = total_revenue\n",
    "            self.best_variables = [v for v, inc in self.included_vars.items() if inc]\n",
    "            self.best_splits = {v: self.splits[v] for v in self.continuous_vars if self.included_vars[v]}\n",
    "            logger.info(f\"Mejor configuración nueva: reward={self.best_reward}, clusters={num_clusters}\")\n",
    "\n",
    "        # Avanzar paso\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.max_steps\n",
    "        truncated = False\n",
    "\n",
    "        # Actualizar estado observable\n",
    "        self.state = self.get_state()\n",
    "        info = {'total_revenue': total_revenue, 'num_clusters': num_clusters}\n",
    "        return self.state, reward, done, truncated, info\n",
    "    \n",
    "    def apply_action(self, action):\n",
    "        \"\"\"\n",
    "        Aplica 'toggle_variable' o 'adjust_splits' sobre la configuración actual.\n",
    "        \"\"\"\n",
    "        action_type, var, params = action\n",
    "        logger.info(f\"Aplicando acción '{action_type}' sobre variable '{var}' con parámetros {params}\")\n",
    "\n",
    "        if action_type == 'toggle_variable':\n",
    "            # Incluir o excluir la variable\n",
    "            self.included_vars[var] = 1 - self.included_vars[var]\n",
    "            logger.debug(f\"Variable '{var}' estado incluido={self.included_vars[var]}\")\n",
    "            if not self.included_vars[var]:\n",
    "                # Al excluir, eliminamos cortes si existían\n",
    "                self.splits[var] = []\n",
    "\n",
    "        elif action_type == 'adjust_splits':\n",
    "            # Sólo para continuas incluidas\n",
    "            if var not in self.continuous_vars or not self.included_vars.get(var, 0):\n",
    "                logger.warning(f\"No puede ajustar splits para '{var}': no es continua o no está incluida.\")\n",
    "                return\n",
    "\n",
    "            op = params.get('operation')\n",
    "            if op == 'increase':\n",
    "                if len(self.splits[var]) < self.max_splits:\n",
    "                    self.add_split(var)\n",
    "                else:\n",
    "                    logger.warning(f\"Máximo de splits alcanzado para '{var}' ({self.max_splits}).\")\n",
    "\n",
    "            elif op == 'decrease':\n",
    "                if len(self.splits[var]) > self.min_splits:\n",
    "                    self.remove_split(var)\n",
    "                else:\n",
    "                    logger.warning(f\"Mínimo de splits alcanzado para '{var}' ({self.min_splits}).\")\n",
    "\n",
    "            elif op == 'move':\n",
    "                idx = params.get('index', 0)\n",
    "                amt = params.get('amount', 0)\n",
    "                if 0 <= idx < len(self.splits[var]):\n",
    "                    self.move_split(var, idx, amt)\n",
    "                else:\n",
    "                    logger.warning(f\"Índice {idx} inválido para mover split en '{var}'.\")\n",
    "\n",
    "            else:\n",
    "                logger.error(f\"Operación desconocida '{op}' para adjust_splits.\")\n",
    "        else:\n",
    "            logger.error(f\"Tipo de acción desconocido: {action_type}\")\n",
    "    \n",
    "    def sort_splits(self, var):\n",
    "        \"\"\"Ordena ascendentemente los valores de splits[var].\"\"\"\n",
    "        self.splits[var].sort()\n",
    "        logger.debug(f\"Splits ordenados para '{var}': {self.splits[var]}\")\n",
    "\n",
    "    def remove_split(self, var):\n",
    "        \"\"\"Elimina el último split de la lista si existe.\"\"\"\n",
    "        if not self.splits[var]:\n",
    "            logger.warning(f\"No hay splits para eliminar en '{var}'.\")\n",
    "            return\n",
    "        removed = self.splits[var].pop()\n",
    "        logger.info(f\"Split eliminado para '{var}': valor={removed}\")\n",
    "\n",
    "    def add_split(self, var):\n",
    "        \"\"\"Agrega un nuevo split en el punto medio de la mayor brecha disponible.\"\"\"\n",
    "        if len(self.splits[var]) >= self.max_splits:\n",
    "            logger.warning(f\"Máximo de splits ({self.max_splits}) alcanzado en '{var}'.\")\n",
    "            return\n",
    "        current = sorted(self.splits[var])\n",
    "        min_v, max_v = self.data[var].min(), self.data[var].max()\n",
    "        points = [min_v] + current + [max_v]\n",
    "        # Calcular brechas\n",
    "        gaps = [(points[i], points[i+1]) for i in range(len(points)-1)]\n",
    "        a, b = max(gaps, key=lambda x: x[1] - x[0])\n",
    "        new = (a + b) / 2\n",
    "        self.splits[var].append(new)\n",
    "        self.sort_splits(var)\n",
    "        logger.info(f\"Agregado split para '{var}' en {new}\")\n",
    "\n",
    "    def move_split(self, var, index, amount):\n",
    "        \"\"\"Mueve el split en 'index' por 'amount' pasos de tamaño proporcional al rango.\"\"\"\n",
    "        if index < 0 or index >= len(self.splits[var]):\n",
    "            logger.warning(f\"Índice {index} fuera de rango en '{var}'.\")\n",
    "            return\n",
    "        min_v, max_v = self.data[var].min(), self.data[var].max()\n",
    "        step = (max_v - min_v) / 20  # paso de 5% rango\n",
    "        old = self.splits[var][index]\n",
    "        new = min(max(old + amount * step, min_v), max_v)\n",
    "        self.splits[var][index] = new\n",
    "        self.sort_splits(var)\n",
    "        logger.info(f\"Split movido para '{var}' índice {index}: {old} -> {new}\")\n",
    "\n",
    "    def format_splits(self, var):\n",
    "        \"\"\"Devuelve lista de diccionarios con los valores de splits.\"\"\"\n",
    "        return [{'value': v} for v in self.splits[var]]\n",
    "\n",
    "    def perform_clustering(self):\n",
    "        \"\"\"Agrupa el DataFrame según variables incluidas y splits definidos.\"\"\"\n",
    "        logger.info(\"Realizando clustering...\")\n",
    "        df = self.data.copy()\n",
    "        for var in self.variables:\n",
    "            if not self.included_vars[var]:\n",
    "                continue\n",
    "            if var in self.categorical_vars:\n",
    "                df[var + '_cluster'] = df[var]\n",
    "                logger.debug(f\"Categórica '{var}' agrupada por categorías: {df[var + '_cluster'].unique()}\")\n",
    "            else:\n",
    "                splits = sorted(self.splits[var])\n",
    "                if not splits:\n",
    "                    df[var + '_cluster'] = 0\n",
    "                else:\n",
    "                    bins = [-np.inf] + splits + [np.inf]\n",
    "                    labels = [f\"{var}_bin_{i}\" for i in range(len(bins)-1)]\n",
    "                    df[var + '_cluster'] = pd.cut(df[var], bins=bins, labels=labels)\n",
    "                    logger.debug(f\"Splits para '{var}': {self.splits[var]}\")\n",
    "        cluster_cols = [v + '_cluster' for v in self.variables if self.included_vars[v]]\n",
    "        if cluster_cols:\n",
    "            df['category'] = df[cluster_cols].astype(str).agg(' '.join, axis=1)\n",
    "            df['cluster_code'] = df['category'].astype('category').cat.codes\n",
    "            df['categoria_clusterizacion_numerica'] = df['cluster_code']\n",
    "            num = df['cluster_code'].nunique()\n",
    "            logger.info(f\"Clusters formados: {num}\")\n",
    "        else:\n",
    "            df['cluster_code'] = 0\n",
    "            df['categoria_clusterizacion_numerica'] = df['cluster_code']\n",
    "            logger.debug(\"Sin variables incluidas, todos en cluster 0.\")\n",
    "        self.current_clusters = df[['rut', 'cluster_code']]\n",
    "        return df\n",
    "\n",
    "    def function_estimar_elasticidad(self, df_estimar_elasticidad):\n",
    "        logger.info(\"Estimando elasticidad...\")\n",
    "\n",
    "        # Obtener los números únicos de cada cluster\n",
    "        cluster_numbers = df_estimar_elasticidad['categoria_clusterizacion_numerica'].unique()\n",
    "        logger.debug(f\"Número de clusters para estimar elasticidad: {len(cluster_numbers)}\")\n",
    "\n",
    "        # Definir la función que procesará un solo cluster\n",
    "        def process_cluster(cluster_num):\n",
    "            logger.debug(f\"Procesando cluster {cluster_num}...\")\n",
    "            # Filtrar los datos correspondientes al cluster actual\n",
    "            df_cluster = df_estimar_elasticidad[df_estimar_elasticidad['categoria_clusterizacion_numerica'] == cluster_num].copy()\n",
    "\n",
    "            # Asegurarse de que existen datos para ambos casos: venta == 1 y venta == 0\n",
    "            if df_cluster.empty or df_cluster['venta'].isnull().all():\n",
    "                logger.warning(f\"Cluster {cluster_num} está vacío o todas las ventas son nulas. Se salta.\")\n",
    "                return None  # Retornar None para indicar que no hay resultados para este cluster\n",
    "\n",
    "            # Remover filas donde 'venta' o 'Tasa_Simulado' son nulos o infinitos\n",
    "            df_cluster = df_cluster.replace([np.inf, -np.inf], np.nan)\n",
    "            df_cluster = df_cluster.dropna(subset=['venta', 'Tasa_Simulado', 'Plazo_Simulado', 'Monto_Simulado', 'Probabilidad_No_Pago'])\n",
    "\n",
    "            # Saltar el cluster si no hay suficientes puntos de datos\n",
    "            if df_cluster.shape[0] < 10:\n",
    "                logger.warning(f\"Cluster {cluster_num} tiene menos de 10 registros después de limpiar. Se salta.\")\n",
    "                return None\n",
    "\n",
    "            # Extraer las variables 'venta' (como variable dependiente) y 'Tasa_Simulado' (como predictor)\n",
    "            y = df_cluster['venta']\n",
    "            X = df_cluster[['Tasa_Simulado']]\n",
    "\n",
    "            # Añadir un término constante para el intercepto\n",
    "            X = sm.add_constant(X)\n",
    "\n",
    "            # Remover filas con valores NaN o Inf en X o y\n",
    "            is_finite = np.isfinite(X).all(1) & np.isfinite(y)\n",
    "            X = X[is_finite]\n",
    "            y = y[is_finite]\n",
    "\n",
    "            # Asegurarse de que después de remover NaN/Inf, todavía hay suficientes datos\n",
    "            if len(y) < 10:\n",
    "                logger.warning(f\"Cluster {cluster_num} tiene menos de 10 registros después de filtrar finitos. Se salta.\")\n",
    "                return None\n",
    "\n",
    "            # Ajustar el modelo de regresión logística\n",
    "            logit_model = sm.Logit(y, X)\n",
    "            try:\n",
    "                result = logit_model.fit(disp=0)\n",
    "                logger.debug(f\"Modelo ajustado para cluster {cluster_num}.\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"No se pudo ajustar el modelo para el cluster {cluster_num}: {e}\")\n",
    "                return None\n",
    "\n",
    "            # Crear una cuadrícula de valores de 'Tasa_Simulado' para predicciones\n",
    "            tasa_min = df_cluster['Tasa_Simulado'].min()\n",
    "            tasa_max = df_cluster['Tasa_Simulado'].max()\n",
    "            tasas_grid = np.linspace(tasa_min, tasa_max, 105)\n",
    "\n",
    "            # Predecir la probabilidad de aceptación usando el modelo ajustado\n",
    "            X_grid = sm.add_constant(tasas_grid)\n",
    "            acceptance_probability = result.predict(X_grid)\n",
    "\n",
    "            # Asegurar que las probabilidades están en el rango [0, 1]\n",
    "            acceptance_probability = np.clip(acceptance_probability, 0, 1)\n",
    "\n",
    "            # Calcular valores medios necesarios para el cálculo de revenue\n",
    "            n = df_cluster['Plazo_Simulado'].mean()\n",
    "            vp = df_cluster['Monto_Simulado'].mean()\n",
    "            pnp = df_cluster['Probabilidad_No_Pago'].mean()\n",
    "            data = {\n",
    "                'Plazo_Simulado_medio': n, \n",
    "                'Monto_Simulado_medio': vp, \n",
    "                'Probabilidad_No_Pago_media': pnp\n",
    "            }\n",
    "\n",
    "            # Calcular el revenue potencial\n",
    "            i = tasas_grid / 100  # Convertir a decimal\n",
    "            one_plus_i_pow_n = np.power(1 + i, n)\n",
    "            annuity_factor = (i * one_plus_i_pow_n) / (one_plus_i_pow_n - 1)\n",
    "            revenue = (n * vp * annuity_factor) - vp\n",
    "            potential_revenue = revenue * (1 - pnp)\n",
    "\n",
    "            # Calcular el promedio de simulaciones por fecha\n",
    "            df_cluster_simulaciones_1 = df_cluster[df_cluster['simulo'] == 1]\n",
    "            num_dates = df_cluster_simulaciones_1['fecha'].nunique()\n",
    "            total_simulaciones = df_cluster_simulaciones_1['simulo'].sum()\n",
    "            simulaciones_medias = total_simulaciones / num_dates if num_dates else 0\n",
    "\n",
    "            # Saltar el cluster si no hay simulaciones\n",
    "            if simulaciones_medias == 0:\n",
    "                logger.warning(f\"Cluster {cluster_num} no tiene simulaciones medias. Se salta.\")\n",
    "                return None\n",
    "\n",
    "            # Calcular el revenue esperado\n",
    "            expected_revenue = acceptance_probability * potential_revenue * simulaciones_medias\n",
    "\n",
    "            # Encontrar la tasa que maximiza el revenue esperado\n",
    "            idx_max = np.argmax(expected_revenue)\n",
    "            max_price = tasas_grid[idx_max]\n",
    "            max_expected_revenue = expected_revenue[idx_max]\n",
    "\n",
    "            # Probabilidad de aceptación en la tasa óptima\n",
    "            prob_aceptacion_optima = acceptance_probability[idx_max]\n",
    "\n",
    "            # Número esperado de créditos aceptados\n",
    "            num_creditos_aceptados = round(prob_aceptacion_optima * simulaciones_medias)\n",
    "\n",
    "            # Número de clientes únicos en el cluster\n",
    "            num_clients = df_cluster['rut'].nunique()\n",
    "\n",
    "            # Imprimir resultados para cada cluster\n",
    "            logger.info(f'Cluster {cluster_num}:')\n",
    "            logger.info(f'- Precio Máx. Revenue Esperado = {max_price:.2f}%')\n",
    "            logger.info(f'- Revenue Esperado Máximo = {max_expected_revenue:,.2f}')\n",
    "            logger.info(f'- Número de clientes en el cluster = {num_clients}')\n",
    "            logger.info(f'- Número de simulaciones en el cluster = {simulaciones_medias:.2f}')\n",
    "            logger.info(f'- Probabilidad de aceptación en el precio óptimo = {prob_aceptacion_optima:.4f}')\n",
    "            logger.info(f'- Número esperado de créditos aceptados = {num_creditos_aceptados}')\n",
    "            logger.info(f'- Monto medio simulado = {data[\"Monto_Simulado_medio\"]:,.2f}')\n",
    "            logger.info(f'- Plazo medio simulado = {data[\"Plazo_Simulado_medio\"]:,.2f}')\n",
    "            logger.info(f'- Probabilidad de no pago media = {data[\"Probabilidad_No_Pago_media\"]:.4f}\\n')\n",
    "\n",
    "            # Preparar los resultados para este cluster\n",
    "            cluster_result = {\n",
    "                'categoria_clusterizacion_numerica': cluster_num,\n",
    "                'tasa_optima': max_price,\n",
    "                'probabilidad_aceptacion_optima': prob_aceptacion_optima,\n",
    "                'revenue_esperado_maximo': max_expected_revenue,\n",
    "                'numero_clientes': num_clients,\n",
    "                'numero_simulaciones_medias': simulaciones_medias,\n",
    "                'numero_creditos_esperados': num_creditos_aceptados,\n",
    "                'monto_medio_simulado': data[\"Monto_Simulado_medio\"],\n",
    "                'plazo_medio_simulado': data[\"Plazo_Simulado_medio\"],\n",
    "                'probabilidad_no_pago_media': data[\"Probabilidad_No_Pago_media\"]\n",
    "            }\n",
    "\n",
    "            return cluster_result\n",
    "\n",
    "        # Ejecutar el procesamiento de clusters en paralelo\n",
    "        num_cores = -1  # Usar todos los núcleos disponibles\n",
    "        results = Parallel(n_jobs=num_cores)(\n",
    "            delayed(process_cluster)(cluster_num) for cluster_num in cluster_numbers\n",
    "        )\n",
    "\n",
    "        # Filtrar los resultados que no son None\n",
    "        cluster_results = [res for res in results if res is not None]\n",
    "\n",
    "        # Si no hay resultados, retornar valores por defecto\n",
    "        if not cluster_results:\n",
    "            logger.warning(\"No se obtuvieron resultados de elasticidad para ningún cluster.\")\n",
    "            total_revenue = 0\n",
    "            total_clientes = 0\n",
    "            total_simulaciones = 0\n",
    "            total_creditos = 0\n",
    "            df_cluster_results = pd.DataFrame()\n",
    "        else:\n",
    "            # Crear un DataFrame a partir de cluster_results\n",
    "            df_cluster_results = pd.DataFrame(cluster_results)\n",
    "\n",
    "            # Imprimir resultados globales\n",
    "            total_revenue = df_cluster_results['revenue_esperado_maximo'].sum()\n",
    "            total_clientes = df_cluster_results['numero_clientes'].sum()\n",
    "            total_simulaciones = df_cluster_results['numero_simulaciones_medias'].sum()\n",
    "            total_creditos = df_cluster_results['numero_creditos_esperados'].sum()\n",
    "\n",
    "            logger.info(f\"El revenue total esperado es: {total_revenue:,.2f} con un total de {total_clientes} clientes, \"\n",
    "                        f\"{total_simulaciones:,.2f} simulaciones, y {total_creditos} créditos.\")\n",
    "\n",
    "        # Incorporar los resultados por cluster de 'df_cluster_results' a 'df_estimar_elasticidad'\n",
    "        if not df_cluster_results.empty:\n",
    "            df_estimar_elasticidad = df_estimar_elasticidad.merge(\n",
    "                df_cluster_results[['categoria_clusterizacion_numerica', 'tasa_optima', 'probabilidad_aceptacion_optima']],\n",
    "                on='categoria_clusterizacion_numerica', \n",
    "                how='left'\n",
    "            )\n",
    "        else:\n",
    "            df_estimar_elasticidad['tasa_optima'] = np.nan\n",
    "            df_estimar_elasticidad['probabilidad_aceptacion_optima'] = np.nan\n",
    "\n",
    "        return {\n",
    "            'df_estimar_elasticidad': df_estimar_elasticidad,\n",
    "            'total_revenue': total_revenue,\n",
    "            'total_clientes': total_clientes,\n",
    "            'total_simulaciones': total_simulaciones,\n",
    "            'total_creditos': total_creditos\n",
    "        }\n",
    "    \n",
    "    def function_estimar_respuesta_a_tratamiento(self, df_estimar_elasticidad, df_simulaciones_info): #df1 es df_estimar_elasticidad y df2 es df_simulaciones_info\n",
    "        # Paso 1: Preparación de datos y mapeo de clusters\n",
    "        # Eliminar duplicados en 'df1' para tener un valor único de 'categoria_clusterizacion_numerica' por cada 'rut'.\n",
    "        df_estimar_elasticidad_unique = df_estimar_elasticidad.drop_duplicates(subset='rut')\n",
    "\n",
    "        # Crear un mapeo de 'rut' a 'categoria_clusterizacion_numerica' para asociar cada cliente a su cluster numérico.\n",
    "        rut_cluster_map = df_estimar_elasticidad_unique.set_index('rut')['categoria_clusterizacion_numerica']\n",
    "\n",
    "        # Mapear la categoría de cluster a cada 'rut' en 'df2' usando el mapeo creado\n",
    "        df_simulaciones_info['categoria_clusterizacion_numerica'] = df_simulaciones_info['rut'].map(rut_cluster_map)\n",
    "\n",
    "        # Eliminar filas donde 'categoria_clusterizacion_numerica' es nulo, es decir, aquellos 'rut' sin mapeo de cluster.\n",
    "        df_simulaciones_info = df_simulaciones_info.dropna(subset=['categoria_clusterizacion_numerica'])\n",
    "\n",
    "        # Conversión de tipos de datos\n",
    "        # Convertir 'categoria_clusterizacion_numerica' a entero para garantizar un tipo de dato consistente.\n",
    "        df_simulaciones_info['categoria_clusterizacion_numerica'] = df_simulaciones_info['categoria_clusterizacion_numerica'].astype(int)\n",
    "\n",
    "        # Convertir 'simulo' a numérico, reemplazando valores nulos por 0 y asegurando que sea un tipo de dato entero.\n",
    "        df_simulaciones_info['simulo'] = pd.to_numeric(df_simulaciones_info['simulo'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "        # Convertir 'Tratamiento' a tipo de categoría para optimizar espacio y realizar operaciones categóricas.\n",
    "        df_simulaciones_info['Tratamiento'] = df_simulaciones_info['Tratamiento'].astype('category')\n",
    "\n",
    "        # Paso 2: Calcular el caso total (entradas por tratamiento sin importar el valor de 'simulo')\n",
    "        # Agrupar por 'categoria_clusterizacion_numerica' y 'Tratamiento' para contar el número total de registros en cada combinación.\n",
    "        total_entries_per_cluster_treatment = df_simulaciones_info.groupby(['categoria_clusterizacion_numerica', 'Tratamiento']).size().reset_index(name='caso_total')\n",
    "\n",
    "        # Paso 3: Calcular el caso favorable (entradas por tratamiento cuando 'simulo' == 1)\n",
    "        # Filtrar filas donde 'simulo' es 1 (clientes que realizaron una simulación)\n",
    "        df_simulations = df_simulaciones_info[df_simulaciones_info['simulo'] == 1]\n",
    "\n",
    "        # Agrupar por 'categoria_clusterizacion_numerica' y 'Tratamiento' para contar el número de registros favorables (simulaciones).\n",
    "        favorable_entries_per_cluster_treatment = df_simulations.groupby(['categoria_clusterizacion_numerica', 'Tratamiento']).size().reset_index(name='caso_favorable')\n",
    "\n",
    "        # Paso 4: Calcular la probabilidad de simulación como caso favorable / caso total\n",
    "        # Realizar un merge entre 'total_entries_per_cluster_treatment' y 'favorable_entries_per_cluster_treatment' en las columnas de cluster y tratamiento.\n",
    "        df_probabilities = total_entries_per_cluster_treatment.merge(\n",
    "            favorable_entries_per_cluster_treatment,\n",
    "            on=['categoria_clusterizacion_numerica', 'Tratamiento'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Llenar valores nulos en 'caso_favorable' con 0, asegurando que solo las columnas numéricas estén afectadas.\n",
    "        df_probabilities['caso_favorable'] = df_probabilities['caso_favorable'].fillna(0).astype(int)\n",
    "\n",
    "        # Asegurar que 'caso_total' sea de tipo entero para evitar inconsistencias en los conteos.\n",
    "        df_probabilities['caso_total'] = df_probabilities['caso_total'].astype(int)\n",
    "\n",
    "        # Calcular la probabilidad de simulación como el cociente entre 'caso_favorable' y 'caso_total'.\n",
    "        df_probabilities['probabilidad_simular'] = df_probabilities['caso_favorable'] / df_probabilities['caso_total']\n",
    "\n",
    "        # Organizar las columnas del DataFrame resultante para facilitar su análisis.\n",
    "        df_probabilities = df_probabilities[[\n",
    "            'categoria_clusterizacion_numerica',\n",
    "            'Tratamiento',\n",
    "            'probabilidad_simular',\n",
    "            'caso_favorable',\n",
    "            'caso_total'\n",
    "        ]]\n",
    "\n",
    "        logger.info(\"Estimación de respuesta a tratamientos completada.\")\n",
    "        return df_probabilities\n",
    "\n",
    "    def function_modelo_asignacion_tratamientos(self, df_cluster_info, df_probabilities_treatment, df_rut_info, costo_sms, capacidad_ejecutivos):\n",
    "        logger.info(\"Iniciando modelo de asignación de tratamientos...\")\n",
    "        try:\n",
    "            # Definir el mapeo de tratamientos\n",
    "            tratamiento_map = {  # Mapeo de los tratamientos específicos a identificadores numéricos\n",
    "                \"Ejecutivo=0, Correos=0\": 1, \"Ejecutivo=0, Correos=1\": 2,\n",
    "                \"Ejecutivo=0, Correos=2\": 3, \"Ejecutivo=0, Correos=3\": 4,\n",
    "                \"Ejecutivo=0, Correos=4\": 5, \"Ejecutivo=1, Correos=0\": 6,\n",
    "                \"Ejecutivo=1, Correos=1\": 7, \"Ejecutivo=1, Correos=2\": 8\n",
    "            }\n",
    "\n",
    "            # Parámetros\n",
    "            costosms = costo_sms  # Costo de cada mensaje SMS\n",
    "            capacidad_ejecutivos = capacidad_ejecutivos  # Capacidad máxima en términos de tiempo de los ejecutivos\n",
    "\n",
    "            # Paso 1: Procesar probabilidades y asignar IDs de tratamiento\n",
    "            df_probabilities = df_probabilities_treatment.copy()\n",
    "            df_probabilities['tratamiento_id'] = df_probabilities['Tratamiento'].map(tratamiento_map)\n",
    "            if df_probabilities['tratamiento_id'].isnull().any():\n",
    "                logger.warning(\"Algunos tratamientos no fueron mapeados correctamente a 'tratamiento_id'. Revisar 'tratamiento_map'.\")\n",
    "\n",
    "            # Paso 2: Crear lista de tratamientos y combinar con rut_info\n",
    "            df_probabilities['tratamientos'] = df_probabilities[['probabilidad_simular', 'tratamiento_id']].values.tolist()\n",
    "            grouped_prob = df_probabilities.groupby('categoria_clusterizacion_numerica')['tratamientos'].apply(list).reset_index()\n",
    "\n",
    "            df_rut_info = df_rut_info.copy()\n",
    "            df_rut_info = df_rut_info.merge(grouped_prob, on='categoria_clusterizacion_numerica', how='left')\n",
    "            if df_rut_info['tratamientos'].isnull().any():\n",
    "                logger.warning(\"Algunos clusters no tienen tratamientos asignados.\")\n",
    "\n",
    "            # Paso 3: Combinar rut_info con cluster_info\n",
    "            df_cluster_info = df_cluster_info.copy()\n",
    "            df_rut_info = df_rut_info.merge(df_cluster_info, on='categoria_clusterizacion_numerica', how='left')\n",
    "            if df_rut_info.isnull().any().any():\n",
    "                logger.warning(\"Algunas combinaciones de clusters no están completas en rut_info.\")\n",
    "\n",
    "            # Paso 3.5: Agrupar información por cluster en 'rut_info'\n",
    "            df_grouped = df_rut_info.groupby('categoria_clusterizacion_numerica').agg({\n",
    "                'Probabilidad_No_Pago': 'mean',  # Promedio de probabilidad de no pago\n",
    "                'tratamientos': lambda x: list(x),  # Lista de opciones de tratamiento únicas en cada cluster\n",
    "                'Monto_Simulado_mean': 'mean',\n",
    "                'Plazo_Simulado_mean': 'mean',\n",
    "                'probabilidad_aceptacion_optima': 'mean',\n",
    "                'tasa_optima': 'mean',\n",
    "                'rut': 'count'  # Conteo del número de clientes ('rut') en cada cluster\n",
    "            }).rename(columns={'rut': 'n_clientes'}).reset_index()\n",
    "            logger.debug(f\"Datos agrupados por cluster: {df_grouped.head()}\")\n",
    "\n",
    "            # Paso 4: Calcular 'RC' (Revenue calculado)\n",
    "            df_grouped['tasa_optima'] /= 100  # Convertir tasa óptima a decimal\n",
    "            df_grouped['RC'] = (\n",
    "                (df_grouped['Plazo_Simulado_mean'] * df_grouped['Monto_Simulado_mean'] * df_grouped['tasa_optima'] *\n",
    "                ((1 + df_grouped['tasa_optima']) ** df_grouped['Plazo_Simulado_mean'])) /\n",
    "                (((1 + df_grouped['tasa_optima']) ** df_grouped['Plazo_Simulado_mean']) - 1)\n",
    "            ) - df_grouped['Monto_Simulado_mean']\n",
    "            logger.debug(f\"RC calculado: {df_grouped['RC'].head()}\")\n",
    "\n",
    "            # -------------------------------\n",
    "            # Preparación de datos para optimización\n",
    "            # -------------------------------\n",
    "\n",
    "            try:\n",
    "                # Convertir 'tratamientos' a un arreglo de numpy para mejorar la indexación\n",
    "                profits = np.array([\n",
    "                    [\n",
    "                        row['n_clientes'] * (row['RC'] * (1 - row['Probabilidad_No_Pago']) * row['probabilidad_aceptacion_optima'] * row['tratamientos'][0][t][0]) - \n",
    "                        (row['tratamientos'][0][t][1] * costosms)\n",
    "                        for t in range(8)\n",
    "                    ]\n",
    "                    for _, row in df_grouped.iterrows()\n",
    "                ])\n",
    "                logger.debug(f\"Matriz de beneficios (profits) preparada con forma: {profits.shape}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error al preparar la matriz de beneficios: {e}\")\n",
    "                del df_grouped, df_rut_info, df_probabilities, df_cluster_info\n",
    "                gc.collect()\n",
    "                return {}, 0 # Retornar valores por defecto en caso de error\n",
    "\n",
    "            model = Model(\"Maximizar_Ganancias\")\n",
    "            model.setParam('OutputFlag', 0)  # Disable all output\n",
    "            model.ModelSense = GRB.MAXIMIZE\n",
    "\n",
    "            # Crear variables de decisión y definir el objetivo\n",
    "            n_clients, n_treatments = profits.shape\n",
    "            variables = {}\n",
    "\n",
    "            for i in range(n_clients):\n",
    "                variables[i] = {}\n",
    "                for t in range(n_treatments):\n",
    "                    if profits[i, t] > 0:\n",
    "                        variables[i][t] = model.addVar(vtype=GRB.BINARY, name=f\"x_{i}_{t}\")\n",
    "            logger.debug(f\"Variables de decisión creadas: {len(variables)} clusters con hasta {n_treatments} tratamientos cada uno.\")\n",
    "\n",
    "            # Definir el objetivo\n",
    "            model.setObjective(\n",
    "                quicksum(variables[i][t] * profits[i, t] for i in variables for t in variables[i])\n",
    "            )\n",
    "\n",
    "            # Restricción: Cada cliente recibe exactamente un tratamiento\n",
    "            for i in variables:\n",
    "                model.addConstr(quicksum(variables[i].values()) == 1, name=f\"OneTreatmentPerClient_{i}\")\n",
    "            model.addConstr(\n",
    "                quicksum(variables[i][t] * df_grouped.loc[i, 'n_clientes'] for i in variables for t in variables[i] if t in [5, 6, 7]) <= capacidad_ejecutivos,\n",
    "                name=\"CapacityConstraint\"\n",
    "            )\n",
    "\n",
    "            clusters = df_grouped.groupby(\"categoria_clusterizacion_numerica\").indices\n",
    "            for cluster_id, indices_cluster in clusters.items():\n",
    "                indices_list = list(indices_cluster)\n",
    "                leader_index = indices_list[0]\n",
    "                for t in variables[leader_index]:\n",
    "                    leader_var = variables[leader_index][t]\n",
    "                    for i in indices_list[1:]:\n",
    "                        if t in variables[i]:\n",
    "                            model.addConstr(variables[i][t] == leader_var, name=f\"ClusterConsistency_{cluster_id}_{t}\")\n",
    "            logger.debug(\"Restricciones de consistencia por cluster agregadas.\")\n",
    "\n",
    "            # Optimizar el modelo\n",
    "            try:\n",
    "                model.optimize()\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error durante la optimización con Gurobi: {e}\")\n",
    "                return {}, 0  # Retornar valores por defecto en caso de error\n",
    "\n",
    "            # Verificar si la optimización fue exitosa\n",
    "            if model.Status == GRB.OPTIMAL:\n",
    "\n",
    "                # Asignar tratamientos por cluster basado en los resultados de la optimización\n",
    "                resultados_por_cluster = {}\n",
    "                for cluster_id, indices_cluster in clusters.items():\n",
    "                    leader_index = list(indices_cluster)[0]\n",
    "                    for t in variables[leader_index]:\n",
    "                        if variables[leader_index][t].X > 0.5:\n",
    "                            resultados_por_cluster[cluster_id] = t + 1\n",
    "                            break\n",
    "\n",
    "                # Calcular las ganancias totales\n",
    "                ganancias_totales = model.ObjVal\n",
    "                logger.info(f\"Ganancias totales: {ganancias_totales:.2f}\")\n",
    "\n",
    "                # Calcular el número de ejecutivos usados y restantes\n",
    "                executives_used = sum(\n",
    "                    df_grouped.loc[i, 'n_clientes'] for i in variables for t in variables[i]\n",
    "                    if t in [5, 6, 7] and variables[i][t].X > 0.5\n",
    "                )\n",
    "                executives_remaining = capacidad_ejecutivos - executives_used\n",
    "                self.executives_remaining = executives_remaining\n",
    "                logger.info(f\"Executives used: {executives_used}\")\n",
    "                logger.info(f\"Executives remaining: {executives_remaining}\")\n",
    "            else:\n",
    "                logger.error(\"Optimización no alcanzó una solución óptima.\")\n",
    "                resultados_por_cluster = {}\n",
    "                ganancias_totales = 0\n",
    "            logger.info(\"Optimización completada.\")\n",
    "\n",
    "            return resultados_por_cluster, ganancias_totales\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error en function_modelo_asignacion_tratamientos: {e}\")\n",
    "            return {}, 0  # Retornar valores por defecto en caso de error global\n",
    "\n",
    "    def recalculate_metrics(self, df_clusters):\n",
    "        logger.info(\"Recalculando métricas...\")\n",
    "        df_clusters = df_clusters[['rut', 'categoria_clusterizacion_numerica']]\n",
    "\n",
    "        # Fusionar df_clusters con df_simulaciones_e_informacion_de_clientes_ventas_tratamiento\n",
    "        df_estimar_elasticidad = pd.merge(\n",
    "            df_clusters,\n",
    "            self.df_sim_ventas_tratamiento,\n",
    "            on='rut',\n",
    "            how='left'\n",
    "        )\n",
    "        logger.debug(f\"Datos después de la fusión: {df_estimar_elasticidad.head()}\")\n",
    "\n",
    "        dict_elasticidad = self.function_estimar_elasticidad(df_estimar_elasticidad)\n",
    "        df_elasticidad = dict_elasticidad['df_estimar_elasticidad']\n",
    "        logger.info(f\"total_revenue: {dict_elasticidad['total_revenue']}, total_clientes: {dict_elasticidad['total_clientes']}, total_simulaciones: {dict_elasticidad['total_simulaciones']}, total_creditos: {dict_elasticidad['total_creditos']}\")\n",
    "\n",
    "        df_probabilities = self.function_estimar_respuesta_a_tratamiento(df_elasticidad, self.df_simulaciones_info)\n",
    "        logger.debug(f\"Probabilidades calculadas: {df_probabilities.head()}\")\n",
    "\n",
    "        # Calcular los promedios para 'Monto_Simulado' y 'Plazo_Simulado' por categoría\n",
    "        df_elasticidad[['Monto_Simulado_mean', 'Plazo_Simulado_mean']] = df_elasticidad.groupby('categoria_clusterizacion_numerica')[['Monto_Simulado', 'Plazo_Simulado']].transform('mean')\n",
    "        logger.debug(f\"Promedios calculados: {df_elasticidad[['Monto_Simulado_mean', 'Plazo_Simulado_mean']].head()}\")\n",
    "\n",
    "        # Reducir tamaño de los DataFrames a las columnas esenciales\n",
    "        df_estimar_elasticidad_small = df_elasticidad[['categoria_clusterizacion_numerica', 'rut', 'tasa_optima', 'probabilidad_aceptacion_optima', 'Probabilidad_No_Pago', 'Monto_Simulado_mean', 'Plazo_Simulado_mean']]\n",
    "        df_probabilities_small = df_probabilities[['categoria_clusterizacion_numerica', 'probabilidad_simular', 'Tratamiento']]\n",
    "\n",
    "        # Guardar información por cluster, tratamiento y cliente\n",
    "        df_cluster_info = df_estimar_elasticidad_small[['categoria_clusterizacion_numerica', 'Monto_Simulado_mean', 'Plazo_Simulado_mean', 'probabilidad_aceptacion_optima', 'tasa_optima']].drop_duplicates()\n",
    "        df_probabilities_treatment = df_probabilities_small[['categoria_clusterizacion_numerica', 'probabilidad_simular', 'Tratamiento']].drop_duplicates()\n",
    "        df_rut_info = df_estimar_elasticidad_small[['rut', 'categoria_clusterizacion_numerica', 'Probabilidad_No_Pago']].drop_duplicates()\n",
    "\n",
    "        logger.info(\"Llamando al modelo de asignación de tratamientos...\")\n",
    "        # Llamar a la función con los DataFrames procesados\n",
    "        resultados_por_cluster, ganancias_totales = self.function_modelo_asignacion_tratamientos(df_cluster_info, df_probabilities_treatment, df_rut_info, 100, 205000)\n",
    "\n",
    "        logger.info(\"Recalculación de métricas completada.\")\n",
    "        return ganancias_totales, len(resultados_por_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_clientes_rl = df_informacion_de_clientes[['rut', 'Genero', 'Categoria_Digital', 'Elasticidad_Precios', 'Nacionalidad', 'Propension', 'Probabilidad_No_Pago', 'Edad', 'Renta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:38:56,311 - __main__ - INFO - Creando instancia de ClusteringEnv...\n",
      "2025-06-17 11:38:56,314 - __main__ - INFO - Inicializando ClusteringEnv con límite de clusters: 25...\n",
      "2025-06-17 11:38:56,346 - __main__ - INFO - Variables categóricas: ['Genero', 'Categoria_Digital', 'Elasticidad_Precios', 'Nacionalidad']\n",
      "2025-06-17 11:38:56,347 - __main__ - INFO - Variables continuas: ['Propension', 'Probabilidad_No_Pago', 'Edad', 'Renta']\n",
      "2025-06-17 11:38:56,348 - __main__ - INFO - Cortes permitidos por variable continua: entre 2 y 3.\n",
      "2025-06-17 11:38:56,350 - __main__ - INFO - Número de acciones posibles: 40\n",
      "2025-06-17 11:38:56,355 - __main__ - INFO - Reiniciando el entorno al estado inicial...\n",
      "2025-06-17 11:38:56,398 - __main__ - INFO - Verificando el entorno con check_env...\n",
      "2025-06-17 11:38:56,399 - __main__ - INFO - Reiniciando el entorno al estado inicial...\n",
      "2025-06-17 11:38:56,416 - __main__ - INFO - Reiniciando el entorno al estado inicial...\n",
      "2025-06-17 11:38:56,446 - __main__ - INFO - Aplicando acción 'adjust_splits' sobre variable 'Propension' con parámetros {'operation': 'move', 'index': 2, 'amount': -1}\n",
      "2025-06-17 11:38:56,447 - __main__ - WARNING - No puede ajustar splits para 'Propension': no es continua o no está incluida.\n",
      "2025-06-17 11:38:56,448 - __main__ - INFO - Aplicando acción 'adjust_splits' sobre variable 'Propension' con parámetros {'operation': 'move', 'index': 2, 'amount': -1}\n",
      "2025-06-17 11:38:56,449 - __main__ - WARNING - No puede ajustar splits para 'Propension': no es continua o no está incluida.\n",
      "2025-06-17 11:38:56,450 - __main__ - INFO - Realizando clustering...\n",
      "2025-06-17 11:38:56,477 - __main__ - INFO - Recalculando métricas...\n",
      "2025-06-17 11:38:56,479 - __main__ - ERROR - Se produjo un error durante la ejecución: \"['categoria_clusterizacion_numerica'] not in index\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\7coto\\AppData\\Local\\Temp\\ipykernel_1124\\172735736.py\", line 82, in <module>\n",
      "    check_env(env, warn=True)\n",
      "  File \"c:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py\", line 481, in check_env\n",
      "    _check_returned_values(env, observation_space, action_space)\n",
      "  File \"c:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py\", line 312, in _check_returned_values\n",
      "    data = env.step(action)\n",
      "  File \"c:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\stable_baselines3\\common\\monitor.py\", line 94, in step\n",
      "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
      "  File \"C:\\Users\\7coto\\AppData\\Local\\Temp\\ipykernel_1124\\1118915906.py\", line 172, in step\n",
      "    total_revenue, num_clusters = self.recalculate_metrics(df)\n",
      "  File \"C:\\Users\\7coto\\AppData\\Local\\Temp\\ipykernel_1124\\1118915906.py\", line 733, in recalculate_metrics\n",
      "    df_clusters = df_clusters[['rut', 'categoria_clusterizacion_numerica']]\n",
      "  File \"c:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py\", line 3767, in __getitem__\n",
      "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
      "  File \"c:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 5877, in _get_indexer_strict\n",
      "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
      "  File \"c:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 5941, in _raise_if_missing\n",
      "    raise KeyError(f\"{not_found} not in index\")\n",
      "KeyError: \"['categoria_clusterizacion_numerica'] not in index\"\n",
      "2025-06-17 11:38:56,812 - __main__ - INFO - Guardando el modelo debido a una interrupción como 'dqn_clustering_agent_error_20250617_113856.zip'...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'gurobipy.Model' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 82\u001b[0m\n\u001b[0;32m     81\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVerificando el entorno con check_env...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m \u001b[43mcheck_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Inicializar y entrenar el agente DQN\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:481\u001b[0m, in \u001b[0;36mcheck_env\u001b[1;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# ============ Check the returned values ===============\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m \u001b[43m_check_returned_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# ==== Check the render method and the declared render modes ====\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:312\u001b[0m, in \u001b[0;36m_check_returned_values\u001b[1;34m(env, observation_space, action_space)\u001b[0m\n\u001b[0;32m    311\u001b[0m action \u001b[38;5;241m=\u001b[39m action_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m--> 312\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m, (\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `step()` method must return five values: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs, reward, terminated, truncated, info. Actual: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m values returned.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    317\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n",
      "Cell \u001b[1;32mIn[39], line 172\u001b[0m, in \u001b[0;36mClusteringEnv.step\u001b[1;34m(self, action_index)\u001b[0m\n\u001b[0;32m    171\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperform_clustering()\n\u001b[1;32m--> 172\u001b[0m total_revenue, num_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Recompensa directa\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[39], line 733\u001b[0m, in \u001b[0;36mClusteringEnv.recalculate_metrics\u001b[1;34m(self, df_clusters)\u001b[0m\n\u001b[0;32m    732\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecalculando métricas...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 733\u001b[0m df_clusters \u001b[38;5;241m=\u001b[39m \u001b[43mdf_clusters\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrut\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategoria_clusterizacion_numerica\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;66;03m# Fusionar df_clusters con df_simulaciones_e_informacion_de_clientes_ventas_tratamiento\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32mc:\\Users\\7coto\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['categoria_clusterizacion_numerica'] not in index\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 159\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Guardar el modelo con timestamp indicando error\u001b[39;00m\n\u001b[0;32m    158\u001b[0m model_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdqn_clustering_agent_error_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 159\u001b[0m \u001b[43msave_model_on_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_file_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 17\u001b[0m, in \u001b[0;36msave_model_on_interrupt\u001b[1;34m(model, file_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_model_on_interrupt\u001b[39m(model, file_name):\n\u001b[0;32m     16\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGuardando el modelo debido a una interrupción como \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(file_name)\n\u001b[0;32m     18\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelo guardado exitosamente como \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\model.pxi:368\u001b[0m, in \u001b[0;36mgurobipy.Model.__getattr__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\model.pxi:1880\u001b[0m, in \u001b[0;36mgurobipy.Model.getAttr\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\attrutil.pxi:26\u001b[0m, in \u001b[0;36mgurobipy._getattrinfo\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'gurobipy.Model' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# Suprimir advertencias de pandas\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "\n",
    "# Configuración básica del logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Función para manejar interrupciones y guardar el modelo\n",
    "def save_model_on_interrupt(model, file_name):\n",
    "    logger.info(f\"Guardando el modelo debido a una interrupción como '{file_name}'...\")\n",
    "    model.save(file_name)\n",
    "    logger.info(f\"Modelo guardado exitosamente como '{file_name}'.\")\n",
    "\n",
    "\n",
    "# Clase personalizada de callback para registrar recompensas\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, log_dir, verbose=0):\n",
    "        super(RewardLoggerCallback, self).__init__(verbose)\n",
    "        self.log_dir = log_dir\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Verificar si ha terminado un episodio\n",
    "        if self.locals.get(\"dones\") and self.locals[\"dones\"][0]:\n",
    "            reward = self.locals[\"rewards\"][0]\n",
    "            length = self.locals[\"infos\"][0].get(\"episode\", {}).get(\"l\", 0)\n",
    "            self.episode_rewards.append(reward)\n",
    "            self.episode_lengths.append(length)\n",
    "            self.episode_count += 1\n",
    "\n",
    "            # Guardar recompensas en un archivo CSV\n",
    "            data = {\n",
    "                \"episode\": self.episode_count,\n",
    "                \"reward\": reward,\n",
    "                \"length\": length,\n",
    "            }\n",
    "            df = pd.DataFrame([data])\n",
    "            csv_file = os.path.join(self.log_dir, \"episode_rewards.csv\")\n",
    "            if not os.path.isfile(csv_file):\n",
    "                df.to_csv(csv_file, index=False)\n",
    "            else:\n",
    "                df.to_csv(csv_file, mode=\"a\", header=False, index=False)\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "# Configurar el directorio de logs y modelos\n",
    "log_dir = \"./logs/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Obtener el timestamp actual\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "try:\n",
    "    # Crear la instancia del entorno\n",
    "    logger.info(\"Creando instancia de ClusteringEnv...\")\n",
    "    env = ClusteringEnv(\n",
    "        df_info_clientes_rl,\n",
    "        df_simulaciones_e_informacion_de_clientes_ventas_tratamiento,\n",
    "        df_simulaciones_info,\n",
    "    )\n",
    "\n",
    "    # Validar si el espacio de acciones está correctamente configurado\n",
    "    if env.action_space.n == 0:\n",
    "        raise ValueError(\n",
    "            \"El espacio de acción está vacío al inicializar el entorno. Revisa la configuración inicial.\"\n",
    "        )\n",
    "\n",
    "    # Envolver el entorno con Monitor para registrar las recompensas\n",
    "    env = Monitor(env, filename=os.path.join(log_dir, \"monitor.csv\"))\n",
    "\n",
    "    # Verificar el entorno (opcional pero recomendado)\n",
    "    logger.info(\"Verificando el entorno con check_env...\")\n",
    "    check_env(env, warn=True)\n",
    "\n",
    "    # Inicializar y entrenar el agente DQN\n",
    "    logger.info(\"Inicializando y entrenando el agente DQN...\")\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        gamma=0.9,  # Reducir gamma a 0.9\n",
    "        exploration_fraction=1.0,  # Mantener alta la tasa de exploración durante todo el entrenamiento\n",
    "        exploration_final_eps=0.5,  # No disminuir epsilon por debajo de 0.5\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Configurar EvalCallback para evaluar el rendimiento del agente durante el entrenamiento\n",
    "    eval_env = ClusteringEnv(\n",
    "        df_info_clientes_rl,\n",
    "        df_simulaciones_e_informacion_de_clientes_ventas_tratamiento,\n",
    "        df_simulaciones_info,\n",
    "    )\n",
    "    eval_env = Monitor(eval_env, filename=os.path.join(log_dir, \"eval_monitor.csv\"))\n",
    "\n",
    "    eval_callback = EvalCallback(\n",
    "        eval_env,\n",
    "        best_model_save_path=log_dir,\n",
    "        log_path=log_dir,\n",
    "        eval_freq=20,  # Frecuencia ajustada para evaluaciones\n",
    "        deterministic=True,\n",
    "        render=False,\n",
    "    )\n",
    "\n",
    "    # Configurar CheckpointCallback para guardar el modelo periódicamente\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=50,  # Guarda el modelo cada 50 timesteps\n",
    "        save_path=log_dir,\n",
    "        name_prefix=f\"dqn_model_checkpoint_{timestamp}\",\n",
    "    )\n",
    "\n",
    "    # Crear una instancia de RewardLoggerCallback\n",
    "    reward_logger = RewardLoggerCallback(log_dir=log_dir)\n",
    "\n",
    "    # Iniciar el entrenamiento del modelo\n",
    "    logger.info(\"Iniciando el entrenamiento del agente DQN...\")\n",
    "    model.learn(\n",
    "        total_timesteps=100,  # Ajusta el número de timesteps según tus necesidades\n",
    "        callback=[eval_callback, checkpoint_callback, reward_logger],\n",
    "    )\n",
    "    logger.info(\"Entrenamiento del agente DQN completado.\")\n",
    "\n",
    "    # Guardar el modelo entrenado con timestamp\n",
    "    model_file_name = f\"dqn_clustering_agent_{timestamp}.zip\"\n",
    "    model.save(model_file_name)\n",
    "    logger.info(f\"Modelo DQN guardado como '{model_file_name}'.\")\n",
    "\n",
    "    # Cargar las recompensas registradas y graficarlas\n",
    "    logger.info(\"Cargando recompensas y generando gráfica de rendimiento...\")\n",
    "    results_df = pd.read_csv(os.path.join(log_dir, \"monitor.csv\"), skiprows=1)\n",
    "    episode_rewards = results_df[\"r\"].tolist()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(episode_rewards)\n",
    "    plt.xlabel(\"Episodio\")\n",
    "    plt.ylabel(\"Recompensa\")\n",
    "    plt.title(\"Recompensa por Episodio durante el Entrenamiento\")\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(log_dir, f\"rewards_plot_{timestamp}.png\"))\n",
    "    plt.close()\n",
    "    logger.info(f\"Gráfica de recompensas guardada como 'rewards_plot_{timestamp}.png'.\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.warning(\"Entrenamiento interrumpido por el usuario.\")\n",
    "    # Guardar el modelo con timestamp indicando interrupción\n",
    "    model_file_name = f\"dqn_clustering_agent_interrupt_{timestamp}.zip\"\n",
    "    save_model_on_interrupt(model, file_name=model_file_name)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Se produjo un error durante la ejecución: {str(e)}\", exc_info=True)\n",
    "    # Guardar el modelo con timestamp indicando error\n",
    "    model_file_name = f\"dqn_clustering_agent_error_{timestamp}.zip\"\n",
    "    save_model_on_interrupt(model, file_name=model_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las recompensas registradas y graficarlas\n",
    "results_df = pd.read_csv(os.path.join(log_dir, \"monitor.csv\"), skiprows=1)\n",
    "episode_rewards = results_df[\"r\"].tolist()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(episode_rewards)\n",
    "plt.xlabel(\"Episodio\")\n",
    "plt.ylabel(\"Recompensa\")\n",
    "plt.title(\"Recompensa por Episodio durante el Entrenamiento\")\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(log_dir, f\"rewards_plot_{timestamp}.png\"))\n",
    "plt.close()\n",
    "logger.info(f\"Gráfica de recompensas guardada como 'rewards_plot_{timestamp}.png'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Suprimir advertencias de pandas\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "# Configuración básica del logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Función para manejar interrupciones y guardar el modelo\n",
    "def save_model_on_interrupt(model, file_name):\n",
    "    logger.info(f\"Guardando el modelo debido a una interrupción como '{file_name}'...\")\n",
    "    model.save(file_name)\n",
    "    logger.info(f\"Modelo guardado exitosamente como '{file_name}'.\")\n",
    "\n",
    "# Clase personalizada de callback para registrar recompensas\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, log_dir, verbose=0):\n",
    "        super(RewardLoggerCallback, self).__init__(verbose)\n",
    "        self.log_dir = log_dir\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Verificar si ha terminado un episodio\n",
    "        if self.locals.get(\"dones\") and self.locals[\"dones\"][0]:\n",
    "            reward = self.locals[\"rewards\"][0]\n",
    "            length = self.locals[\"infos\"][0].get(\"episode\", {}).get(\"l\", 0)\n",
    "            self.episode_rewards.append(reward)\n",
    "            self.episode_lengths.append(length)\n",
    "            self.episode_count += 1\n",
    "\n",
    "            # Guardar recompensas en un archivo CSV\n",
    "            data = {\n",
    "                \"episode\": self.episode_count,\n",
    "                \"reward\": reward,\n",
    "                \"length\": length,\n",
    "            }\n",
    "            df = pd.DataFrame([data])\n",
    "            csv_file = os.path.join(self.log_dir, \"episode_rewards.csv\")\n",
    "            if not os.path.isfile(csv_file):\n",
    "                df.to_csv(csv_file, index=False)\n",
    "            else:\n",
    "                df.to_csv(csv_file, mode=\"a\", header=False, index=False)\n",
    "\n",
    "        return True\n",
    "\n",
    "# Establecer un múltiplo de max_steps para total_timesteps\n",
    "max_steps = 50  # Pasos por episodio\n",
    "episodes_per_block = 5  # Episodios entre evaluaciones\n",
    "eval_freq = max_steps * episodes_per_block  # Evaluar después de 5 episodios\n",
    "save_freq = eval_freq  # Guardar el modelo con la misma frecuencia\n",
    "total_timesteps = eval_freq * 10  # 50 bloques de 5 episodios cada uno\n",
    "\n",
    "# Configurar el directorio de logs y modelos\n",
    "log_dir = \"./logs/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Obtener el timestamp actual\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Ruta al modelo DQN existente\n",
    "existing_model_path = \"./dqn_clustering_agent_interrupt_20241202_005345.zip\"\n",
    "try:\n",
    "    # Crear la instancia del entorno\n",
    "    logger.info(\"Creando instancia de ClusteringEnv...\")\n",
    "    env = ClusteringEnv(\n",
    "        df_info_clientes_rl,\n",
    "        df_simulaciones_e_informacion_de_clientes_ventas_tratamiento,\n",
    "        df_simulaciones_info,\n",
    "    )\n",
    "\n",
    "    # Envolver el entorno con Monitor\n",
    "    env = Monitor(env, filename=os.path.join(log_dir, \"monitor.csv\"))\n",
    "\n",
    "    # Verificar el entorno (opcional pero recomendado)\n",
    "    logger.info(\"Verificando el entorno con check_env...\")\n",
    "    check_env(env, warn=True)\n",
    "\n",
    "    # Cargar el modelo DQN existente\n",
    "    logger.info(f\"Cargando el modelo DQN desde '{existing_model_path}'...\")\n",
    "    model = DQN.load(existing_model_path, env=env,\n",
    "                    gamma=0.95,  # Focus on long-term rewards\n",
    "                    exploration_fraction=0.1,  # Quick transition to exploitation\n",
    "                    exploration_final_eps=0.01)  # Minimal randomness in decisions\n",
    "\n",
    "\n",
    "    # Configurar EvalCallback para evaluar el rendimiento del agente durante el entrenamiento\n",
    "    eval_env = ClusteringEnv(\n",
    "        df_info_clientes_rl,\n",
    "        df_simulaciones_e_informacion_de_clientes_ventas_tratamiento,\n",
    "        df_simulaciones_info,\n",
    "    )\n",
    "    eval_env.max_steps = 50\n",
    "    eval_env = Monitor(eval_env, filename=os.path.join(log_dir, \"eval_monitor.csv\"))\n",
    "\n",
    "    eval_callback = EvalCallback(\n",
    "        eval_env,\n",
    "        best_model_save_path=log_dir,\n",
    "        log_path=log_dir,\n",
    "        eval_freq=eval_freq,  # Frecuencia ajustada\n",
    "        deterministic=True,\n",
    "        render=False,\n",
    "    )\n",
    "\n",
    "    # Configurar CheckpointCallback para guardar el modelo periódicamente\n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=save_freq,  # Frecuencia ajustada\n",
    "        save_path=log_dir,\n",
    "        name_prefix=f\"dqn_model_checkpoint_{timestamp}\",\n",
    "    )\n",
    "\n",
    "\n",
    "    # Crear una instancia de RewardLoggerCallback\n",
    "    reward_logger = RewardLoggerCallback(log_dir=log_dir)\n",
    "\n",
    "    # Continuar el entrenamiento del modelo\n",
    "    logger.info(\"Continuando el entrenamiento del modelo DQN...\")\n",
    "    model.learn(\n",
    "        total_timesteps=total_timesteps,  # Total ajustado\n",
    "        callback=[eval_callback, checkpoint_callback, reward_logger],\n",
    "    )\n",
    "    logger.info(\"Entrenamiento del modelo DQN completado.\")\n",
    "\n",
    "    # Guardar el modelo actualizado con timestamp\n",
    "    updated_model_file_name = f\"dqn_clustering_agent_updated_{timestamp}.zip\"\n",
    "    model.save(updated_model_file_name)\n",
    "    logger.info(f\"Modelo DQN actualizado guardado como '{updated_model_file_name}'.\")\n",
    "\n",
    "    # Cargar las recompensas registradas y graficarlas\n",
    "    logger.info(\"Cargando recompensas y generando gráfica de rendimiento...\")\n",
    "    results_df = pd.read_csv(os.path.join(log_dir, \"monitor.csv\"), skiprows=1)\n",
    "    episode_rewards = results_df[\"r\"].tolist()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(episode_rewards)\n",
    "    plt.xlabel(\"Episodio\")\n",
    "    plt.ylabel(\"Recompensa\")\n",
    "    plt.title(\"Recompensa por Episodio durante el Entrenamiento\")\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(log_dir, f\"rewards_plot_{timestamp}.png\"))\n",
    "    plt.close()\n",
    "    logger.info(f\"Gráfica de recompensas guardada como 'rewards_plot_{timestamp}.png'.\")\n",
    "\n",
    "    # Evaluate the trained model deterministically\n",
    "    logger.info(\"Evaluating the trained model in deterministic mode...\")\n",
    "    deterministic_rewards = []\n",
    "    for _ in range(100):  # Run 100 episodes\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "        deterministic_rewards.append(episode_reward)\n",
    "\n",
    "    average_reward = np.mean(deterministic_rewards)\n",
    "    logger.info(f\"Average reward over 100 deterministic episodes: {average_reward}\")\n",
    "\n",
    "    # Cargar recompensas y generar gráfica de rendimiento\n",
    "    logger.info(\"Cargando recompensas y generando gráfica de rendimiento...\")\n",
    "    results_df = pd.read_csv(os.path.join(log_dir, \"monitor.csv\"), skiprows=1)\n",
    "    episode_rewards = results_df[\"r\"].tolist()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.warning(\"Entrenamiento interrumpido por el usuario.\")\n",
    "    # Guardar el modelo con timestamp indicando interrupción\n",
    "    interrupted_model_file_name = f\"dqn_clustering_agent_interrupt_{timestamp}.zip\"\n",
    "    save_model_on_interrupt(model, file_name=interrupted_model_file_name)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Se produjo un error durante la ejecución: {str(e)}\", exc_info=True)\n",
    "    # Guardar el modelo con timestamp indicando error\n",
    "    error_model_file_name = f\"dqn_clustering_agent_error_{timestamp}.zip\"\n",
    "    save_model_on_interrupt(model, file_name=error_model_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. SIMULACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "df_clientes = pd.read_csv(\"Informacion_Clientes.csv\")\n",
    "df_cluster = pd.read_csv(\"cluster_data_20241202_201001/cluster_info.csv\")\n",
    "df_treatment = pd.read_csv(\"assigned_treatments/assignation_20241202_202153/assigned_treatments.csv\")\n",
    "\n",
    "print(df_cluster.columns)\n",
    "print(df_treatment.columns)\n",
    "\n",
    "df_cluster.dropna(inplace=True)\n",
    "df_treatment.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Renombrar categoria_clusterizacion_numerica a cluster\n",
    "df_cluster = df_cluster.rename(columns={'categoria_clusterizacion_numerica': 'cluster'})\n",
    "\n",
    "# Seleccionar solo las columnas adicionales de df_cluster\n",
    "cluster_additional_cols = [col for col in df_cluster.columns if col not in df_treatment.columns and col != 'cluster']\n",
    "\n",
    "\n",
    "# Realizar el merge utilizando solo las columnas adicionales\n",
    "df_combined = df_treatment.merge(\n",
    "    df_cluster[['cluster'] + cluster_additional_cols],  # cluster y columnas adicionales\n",
    "    on='cluster', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(df_combined.columns)\n",
    "\n",
    "# Dividir tasa_optima por 100 directamente en df_combined\n",
    "df_combined['tasa_optima'] = df_combined['tasa_optima'] / 100\n",
    "\n",
    "# Calcular Monto_Simulado en df_clientes\n",
    "df_clientes['Monto_Simulado'] = (\n",
    "    -866900 \n",
    "    + 0.8845 * df_clientes['Renta'] \n",
    "    + 0.7231 * df_clientes['Oferta_Consumo'] \n",
    "    - 0.105 * df_clientes['Deuda_CMF']\n",
    ")\n",
    "\n",
    "# Añadir Monto_Simulado a df_combined\n",
    "df_combined = df_combined.merge(\n",
    "    df_clientes[['rut', 'Monto_Simulado']], \n",
    "    on='rut', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(df_combined.columns)\n",
    "\n",
    "# Reemplazar valores negativos en Monto_Simulado con 0\n",
    "df_combined['Monto_Simulado'] = df_combined['Monto_Simulado'].clip(lower=0)\n",
    "\n",
    "df_combined['Plazo_Esperado'] = (df_combined['Plazo_Simulado_min'] + df_combined['Plazo_Simulado_max'] + df_combined['Plazo_Simulado_mode'])/3\n",
    "\n",
    "# Calcular RC\n",
    "df_combined['RC'] = (\n",
    "    (df_combined['Plazo_Esperado'] * df_combined['Monto_Simulado'] * df_combined['tasa_optima'] *\n",
    "     ((1 + df_combined['tasa_optima']) ** df_combined['Plazo_Esperado'])) /\n",
    "    (((1 + df_combined['tasa_optima']) ** df_combined['Plazo_Esperado']) - 1)\n",
    "    - df_combined['Monto_Simulado']\n",
    ")\n",
    "\n",
    "# Guardar resultado final\n",
    "df_combined.to_csv(\"info_final.csv\", index=False)\n",
    "\n",
    "####################################################################################################\n",
    "# Carga el archivo CSV en un DataFrame\n",
    "df = pd.read_csv('info_final.csv')\n",
    "\n",
    "####################################################################################################\n",
    "# Definimos tambien el costo de los correos\n",
    "costosms = 100\n",
    "\n",
    "# Mapeo del número de correos por tratamiento\n",
    "correos_por_tratamiento = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 4,\n",
    "    6: 0,\n",
    "    7: 1,\n",
    "    8: 2\n",
    "}\n",
    "\n",
    "# Agregar una columna con el número de correos de acuerdo al tratamiento\n",
    "df['num_correos'] = df['assigned_treatment'].map(correos_por_tratamiento)\n",
    "\n",
    "####################################################################################################\n",
    "# PENDIENTE: EVALUAR SI TRABAJAR SIMPLEMENTE CON RC o para cada cluster definir como tratar los \n",
    "# montos y plazos simulados\n",
    "\n",
    "####################################################################################################\n",
    "# SIMULACIÓN y KPIS:\n",
    "# 1.Calcular el valor esperado de ganancias\n",
    "# 2.Calcular el numero promedio de correos enviados\n",
    "# 3.Simular las ventas segun las variables aleatorias (sacar creditos cursados y valor promedio ganancias)\n",
    "# 4.Sacar desviación estandar \n",
    "\n",
    "#####################################################################################################\n",
    "# 1. Valor esperado ganancias (cambiar al tener el estudio de montos y plazos)\n",
    "# Calcular la ganancia esperada para cada fila considerando los costos de correos\n",
    "df['ganancia_esperada_fila'] = (\n",
    "    df['RC'] * \n",
    "    df['probabilidad_de_simular'] * \n",
    "    df['probabilidad_aceptacion_optima'] * \n",
    "    (1 - df['Probabilidad_No_Pago']) -\n",
    "    (df['num_correos'] * costosms)\n",
    ")\n",
    "\n",
    "# Calcular la ganancia_esperada total\n",
    "ganancia_esperada_total = df['ganancia_esperada_fila'].sum()\n",
    "\n",
    "print(\"Ganancia esperada total:\", ganancia_esperada_total)\n",
    "####################################################################################################\n",
    "# 2. Numero de correos enviados:\n",
    "\n",
    "# Calcular el número promedio de correos enviados\n",
    "promedio_correos = df['num_correos'].mean()\n",
    "\n",
    "# Calcular el total de correos enviados\n",
    "total_correos_enviados = df['num_correos'].sum()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Total de correos enviados:\", total_correos_enviados)\n",
    "print(\"Número promedio de correos enviados:\", promedio_correos)\n",
    "\n",
    "####################################################################################################\n",
    "# 3 y 4. Simulación\n",
    "import numpy as np\n",
    "# Configuración de la simulación\n",
    "num_simulaciones = 100\n",
    "ganancias_simuladas = []\n",
    "tasas_creditos_aceptados = []\n",
    "\n",
    "# Realizar la simulación\n",
    "for _ in range(num_simulaciones):\n",
    "    # Generar plazos simulados con distribución triangular\n",
    "    plazos_simulados = np.random.triangular(\n",
    "        df['Plazo_Simulado_min'],\n",
    "        df['Plazo_Simulado_mode'],\n",
    "        df['Plazo_Simulado_max']\n",
    "    )\n",
    "\n",
    "    # Calcular RC dinámico basado en los plazos simulados\n",
    "    rc_simulado = (\n",
    "        (plazos_simulados * df['Monto_Simulado'] * df['tasa_optima'] *\n",
    "         ((1 + df['tasa_optima']) ** plazos_simulados)) /\n",
    "        (((1 + df['tasa_optima']) ** plazos_simulados) - 1) -\n",
    "        df['Monto_Simulado']\n",
    "    )\n",
    "\n",
    "    # Simular variables aleatorias (binomiales)\n",
    "    sim_probabilidad_de_simular = np.random.binomial(1, df['probabilidad_de_simular'])\n",
    "    sim_probabilidad_aceptacion_optima = np.random.binomial(1, df['probabilidad_aceptacion_optima'])\n",
    "    sim_Probabilidad_No_Pago = np.random.binomial(1, df['Probabilidad_No_Pago'])\n",
    "\n",
    "    # Calcular el total de créditos simulados y aceptados\n",
    "    total_creditos_simulados = sim_probabilidad_de_simular.sum()\n",
    "    total_creditos_aceptados = (sim_probabilidad_de_simular * sim_probabilidad_aceptacion_optima).sum()\n",
    "    \n",
    "    # Calcular la tasa de créditos aceptados\n",
    "    tasa_creditos_aceptados = (\n",
    "        total_creditos_aceptados / total_creditos_simulados\n",
    "        if total_creditos_simulados > 0 else 0\n",
    "    )\n",
    "\n",
    "    # Calcular la ganancia esperada para cada fila en esta simulación\n",
    "    ganancia_simulada_fila = (\n",
    "        rc_simulado *\n",
    "        sim_probabilidad_de_simular *\n",
    "        sim_probabilidad_aceptacion_optima *\n",
    "        (1 - sim_Probabilidad_No_Pago) -\n",
    "        (df['num_correos'] * costosms)\n",
    "    )\n",
    "    \n",
    "    # Calcular la ganancia total de esta simulación y almacenarla\n",
    "    ganancia_total_simulada = ganancia_simulada_fila.sum()\n",
    "    ganancias_simuladas.append(ganancia_total_simulada)\n",
    "    tasas_creditos_aceptados.append(tasa_creditos_aceptados)\n",
    "\n",
    "# Calcular el promedio y la desviación estándar de las ganancias simuladas\n",
    "promedio_ganancias = np.mean(ganancias_simuladas)\n",
    "desviacion_ganancias = np.std(ganancias_simuladas)\n",
    "\n",
    "# Calcular el promedio de la tasa de créditos aceptados\n",
    "promedio_tasa_creditos_aceptados = np.mean(tasas_creditos_aceptados)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Promedio de ganancias simuladas:\", promedio_ganancias)\n",
    "print(\"Desviación estándar de ganancias simuladas:\", desviacion_ganancias)\n",
    "print(\"Tasa promedio de créditos aceptados:\", promedio_tasa_creditos_aceptados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
